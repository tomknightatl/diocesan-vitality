# USCCB Development Makefile
# Quick commands for local development

.PHONY: help dev test quick clean install start stop

help: ## Show this help message
	@echo "USCCB Development Commands"
	@echo "========================="
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-15s\033[0m %s\n", $$1, $$2}'

install: ## Install all dependencies
	@echo "ğŸ“¦ Installing Python dependencies..."
	pip install -r requirements.txt
	@if [ -d "frontend" ]; then \
		echo "ğŸ“¦ Installing frontend dependencies..."; \
		cd frontend && npm install; \
	fi
	@echo "âœ… Dependencies installed"

start: ## Start development services
	@echo "ğŸš€ Starting development environment..."
	@python scripts/dev_start.py --backend-only

start-full: ## Start backend and frontend
	@echo "ğŸš€ Starting full development environment..."
	@python scripts/dev_start.py

stop: ## Stop development services
	@echo "ğŸ›‘ Stopping services..."
	@lsof -ti:8000 | xargs -r kill
	@lsof -ti:3000 | xargs -r kill
	@echo "âœ… Services stopped"

test: ## Run all development tests
	@echo "ğŸ§ª Running development tests..."
	@python scripts/dev_test.py --all

test-quick: ## Run quick tests
	@echo "ğŸ§ª Running quick tests..."
	@python scripts/dev_test.py --db --ai --env

dev: ## Quick development setup check
	@echo "ğŸ” Development environment check..."
	@python scripts/dev_test.py --env
	@python scripts/dev_quick.py stats

extract: ## Quick single parish extraction test
	@echo "ğŸƒâ€â™‚ï¸ Quick extraction test..."
	@python scripts/dev_quick.py extract

diocese: ## Quick diocese scan test
	@echo "ğŸ” Quick diocese scan..."
	@python scripts/dev_quick.py diocese

schedule: ## Quick schedule extraction test
	@echo "â° Quick schedule test..."
	@python scripts/dev_quick.py schedule

logs: ## View recent logs
	@python scripts/dev_quick.py logs

stats: ## Show database statistics
	@python scripts/dev_quick.py stats

clean: ## Clean cache and temporary files
	@echo "ğŸ§¹ Cleaning cache and temporary files..."
	@python scripts/dev_quick.py clear-cache
	@find . -name "*.pyc" -delete
	@find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
	@rm -rf .pytest_cache
	@echo "âœ… Cleanup complete"

kill-chrome: ## Kill stuck Chrome processes
	@python scripts/dev_quick.py kill-chrome

restart: ## Restart all services
	@python scripts/dev_quick.py restart

ports: ## Check development port usage
	@python scripts/dev_quick.py ports

pipeline: ## Run full pipeline with monitoring (small test)
	@echo "ğŸš€ Running pipeline test..."
	@python run_pipeline_monitored.py \
		--diocese_id 1 \
		--max_parishes_per_diocese 5 \
		--num_parishes_for_schedule 2 \
		--monitoring_url http://localhost:8000

pipeline-single: ## Run pipeline for single diocese
	@echo "ğŸš€ Running single diocese pipeline..."
	@python run_pipeline_monitored.py \
		--diocese_id $(DIOCESE_ID) \
		--max_parishes_per_diocese 10 \
		--skip_schedules \
		--monitoring_url http://localhost:8000

format: ## Format code with black
	@echo "ğŸ¨ Formatting code..."
	@black . --exclude="venv|node_modules"
	@echo "âœ… Code formatted"

lint: ## Run linting
	@echo "ğŸ” Running linting..."
	@flake8 . --exclude=venv,node_modules --max-line-length=88 --extend-ignore=E203,W503
	@echo "âœ… Linting complete"

env-check: ## Check environment configuration
	@python scripts/dev_test.py --env

db-check: ## Test database connection
	@python scripts/dev_test.py --db

ai-check: ## Test AI API connection
	@python scripts/dev_test.py --ai

webdriver-check: ## Test Chrome WebDriver
	@python scripts/dev_test.py --webdriver

monitor-check: ## Test monitoring integration
	@python scripts/dev_test.py --monitoring

# Infrastructure Commands
# =======================

infra-setup: ## Set up complete infrastructure (all 6 steps, usage: make infra-setup CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸš€ Setting up complete infrastructure for '$$CLUSTER_LABEL'..." && \
	$(MAKE) cluster-create CLUSTER_LABEL=$$CLUSTER_LABEL && \
	$(MAKE) tunnel-create CLUSTER_LABEL=$$CLUSTER_LABEL && \
	$(MAKE) tunnel-verify CLUSTER_LABEL=$$CLUSTER_LABEL && \
	$(MAKE) argocd-install CLUSTER_LABEL=$$CLUSTER_LABEL && \
	$(MAKE) argocd-apps CLUSTER_LABEL=$$CLUSTER_LABEL && \
	$(MAKE) sealed-secrets-create CLUSTER_LABEL=$$CLUSTER_LABEL && \
	$(MAKE) infra-test CLUSTER_LABEL=$$CLUSTER_LABEL && \
	echo "ğŸ‰ Infrastructure setup complete for $$CLUSTER_LABEL!"

cluster-create: ## Step 1: Create cluster and kubectl context (usage: make cluster-create CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸš€ Step 1: Creating cluster and kubectl context for '$$CLUSTER_LABEL'..." && \
	if ! command -v jq >/dev/null 2>&1; then \
		echo "âŒ jq is required for cluster monitoring. Install with: apt-get install jq" && \
		exit 1; \
	fi && \
	START_TIME=$$(date +%s) && \
	TIMEOUT_SECONDS=900 && \
	if [ "$$CLUSTER_LABEL" = "stg" ]; then ENV_DIR="staging"; else ENV_DIR="$$CLUSTER_LABEL"; fi && \
	cd terraform/environments/$$ENV_DIR && \
		echo "â³ Initializing Terraform... ($$(date '+%H:%M:%S'))" && \
		export $$(grep DIGITALOCEAN_TOKEN ../../../.env | xargs) && \
		if ! terraform init; then \
			echo "âŒ FAILED: Terraform initialization failed at $$(date '+%H:%M:%S')" && \
			exit 1; \
		fi && \
		echo "ğŸ”§ Applying Terraform configuration... ($$(date '+%H:%M:%S'))" && \
		if ! terraform apply -target=module.k8s_cluster -auto-approve; then \
			echo "âŒ FAILED: Terraform apply failed at $$(date '+%H:%M:%S')" && \
			echo "ğŸ’¡ Check the error output above for details" && \
			exit 1; \
		fi && \
		echo "ğŸ“‹ Monitoring cluster provisioning status... ($$(date '+%H:%M:%S'))" && \
		CLUSTER_NAME="dv-$$CLUSTER_LABEL" && \
		while true; do \
			CURRENT_TIME=$$(date +%s) && \
			ELAPSED=$$((CURRENT_TIME - START_TIME)) && \
			if [ $$ELAPSED -gt $$TIMEOUT_SECONDS ]; then \
				echo "âŒ Timeout: Cluster creation exceeded 15 minutes" && \
				exit 1; \
			fi && \
			STATUS=$$(doctl kubernetes cluster get $$CLUSTER_NAME -o json 2>/dev/null | jq -r '.[0].status.state // "not_found"') && \
			if [ "$$STATUS" = "running" ]; then \
				echo "âœ… Cluster is running! (Total time: $$((ELAPSED/60))m $$((ELAPSED%60))s)" && \
				break; \
			elif [ "$$STATUS" = "provisioning" ]; then \
				echo "â³ Cluster still provisioning... ($$((ELAPSED/60))m $$((ELAPSED%60))s elapsed, $$(date '+%H:%M:%S'))" && \
				sleep 30; \
			elif [ "$$STATUS" = "not_found" ]; then \
				echo "â³ Waiting for cluster to appear in DigitalOcean... ($$((ELAPSED/60))m $$((ELAPSED%60))s elapsed)" && \
				sleep 15; \
			else \
				echo "âŒ Unexpected cluster status: $$STATUS" && \
				exit 1; \
			fi; \
		done && \
		echo "ğŸ”— Configuring kubectl access... ($$(date '+%H:%M:%S'))" && \
		doctl kubernetes cluster kubeconfig save dv-$$CLUSTER_LABEL && \
		kubectl config use-context do-nyc2-dv-$$CLUSTER_LABEL && \
		echo "ğŸ” Verifying cluster nodes... ($$(date '+%H:%M:%S'))" && \
		kubectl get nodes && \
		echo "ğŸ·ï¸  Labeling cluster with environment label... ($$(date '+%H:%M:%S'))" && \
		kubectl create secret generic cluster-info \
			--from-literal=environment=$$CLUSTER_LABEL \
			--from-literal=cluster-name=dv-$$CLUSTER_LABEL \
			-n default --dry-run=client -o yaml | kubectl apply -f -
	@echo "âœ… Step 1 Complete: Cluster created and labeled"

tunnel-create: ## Step 2: Create Cloudflare tunnel and DNS records (usage: make tunnel-create CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸš€ Step 2: Creating Cloudflare tunnel for '$$CLUSTER_LABEL'..." && \
	echo "ğŸ§¹ Cleaning up any stale tunnel state..." && \
	if [ "$$CLUSTER_LABEL" = "stg" ]; then ENV_DIR="staging"; else ENV_DIR="$$CLUSTER_LABEL"; fi && \
	cd terraform/environments/$$ENV_DIR && \
		echo "ğŸ”§ Setting up environment variables... ($$(date '+%H:%M:%S'))" && \
		export $$(grep CLOUDFLARE_API_TOKEN ../../../.env | xargs) && \
		echo "ğŸ§¹ Cleaning up stale tunnel state... ($$(date '+%H:%M:%S'))" && \
		if ! terraform state list | grep "module.cloudflare_tunnel" | xargs -r terraform state rm; then \
			echo "ğŸ’¡ No stale tunnel state to clean" && true; \
		fi && \
		echo "ğŸš€ Applying Cloudflare tunnel configuration... ($$(date '+%H:%M:%S'))" && \
		if ! terraform apply -target=module.cloudflare_tunnel -auto-approve; then \
			echo "âŒ FAILED: Tunnel creation failed at $$(date '+%H:%M:%S')" && \
			echo "ğŸ’¡ Check the error output above for details" && \
			exit 1; \
		fi
	@echo "âœ… Step 2 Complete: Cloudflare tunnel created for $$CLUSTER_LABEL"

argocd-install: ## Step 3: Install ArgoCD via Helm with proper configuration (usage: make argocd-install CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸš€ Step 3: Installing ArgoCD via Helm for '$$CLUSTER_LABEL'..." && \
	echo "ğŸ”§ Switching to cluster context... ($$(date '+%H:%M:%S'))" && \
	if ! kubectl config use-context do-nyc2-dv-$$CLUSTER_LABEL; then \
		echo "âŒ FAILED: Could not switch to kubectl context do-nyc2-dv-$$CLUSTER_LABEL at $$(date '+%H:%M:%S')" && \
		echo "ğŸ’¡ Check if cluster exists: doctl kubernetes cluster list" && \
		exit 1; \
	fi && \
		echo "ğŸ”§ Installing Helm if needed... ($$(date '+%H:%M:%S'))" && \
		if ! $(MAKE) _install-helm; then \
			echo "âŒ FAILED: Helm installation failed at $$(date '+%H:%M:%S')" && \
			exit 1; \
		fi && \
		echo "ğŸ“¦ Adding ArgoCD Helm repository... ($$(date '+%H:%M:%S'))" && \
		if ! helm repo add argo https://argoproj.github.io/argo-helm; then \
			echo "âŒ FAILED: Could not add ArgoCD Helm repository at $$(date '+%H:%M:%S')" && \
			exit 1; \
		fi && \
		if ! helm repo update; then \
			echo "âŒ FAILED: Helm repo update failed at $$(date '+%H:%M:%S')" && \
			exit 1; \
		fi && \
		echo "ğŸ—ï¸  Creating ArgoCD namespace... ($$(date '+%H:%M:%S'))" && \
		if ! kubectl create namespace argocd --dry-run=client -o yaml | kubectl apply -f -; then \
			echo "âŒ FAILED: Could not create argocd namespace at $$(date '+%H:%M:%S')" && \
			exit 1; \
		fi && \
		echo "ğŸš€ Installing ArgoCD with values-$$CLUSTER_LABEL.yaml... ($$(date '+%H:%M:%S'))" && \
		if ! helm upgrade --install argocd argo/argo-cd \
			--namespace argocd \
			--values k8s/infrastructure/argocd/values-$$CLUSTER_LABEL.yaml \
			--wait --timeout=10m; then \
			echo "âŒ FAILED: ArgoCD Helm installation failed at $$(date '+%H:%M:%S')" && \
			echo "ğŸ’¡ Check Helm values file: k8s/infrastructure/argocd/values-$$CLUSTER_LABEL.yaml" && \
			exit 1; \
		fi && \
		echo "â³ Waiting for ArgoCD server to be ready... ($$(date '+%H:%M:%S'))" && \
		if ! kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=argocd-server -n argocd --timeout=300s; then \
			echo "âŒ FAILED: ArgoCD server pods not ready within 5 minutes at $$(date '+%H:%M:%S')" && \
			echo "ğŸ’¡ Check pod status: kubectl get pods -n argocd" && \
			exit 1; \
		fi && \
		echo "ğŸ”§ Configuring repository access... ($$(date '+%H:%M:%S'))" && \
		TIMEOUT=60 && START_TIME=$$(date +%s) && \
		while ! kubectl get configmap argocd-cm -n argocd >/dev/null 2>&1; do \
			CURRENT_TIME=$$(date +%s) && \
			if [ $$((CURRENT_TIME - START_TIME)) -gt $$TIMEOUT ]; then \
				echo "âŒ FAILED: ArgoCD configmap not available within 60 seconds at $$(date '+%H:%M:%S')" && \
				exit 1; \
			fi && \
			sleep 2; \
		done && \
		sleep 5 && \
		if ! kubectl patch configmap argocd-cm -n argocd --patch '{"data":{"repositories":"- url: https://github.com/tomknightatl/diocesan-vitality.git"}}'; then \
			echo "âŒ FAILED: Could not configure repository access at $$(date '+%H:%M:%S')" && \
			exit 1; \
		fi
	@echo "ğŸ”§ Setting up custom ArgoCD password..."
	@$(MAKE) _setup-argocd-password CLUSTER_LABEL=$$CLUSTER_LABEL
	@echo "ğŸ·ï¸  Registering cluster with ArgoCD..."
	@$(MAKE) _register-cluster-with-argocd CLUSTER_LABEL=$$CLUSTER_LABEL
	@echo "ğŸš€ Deploying App-of-Apps for ApplicationSets..."
	@$(MAKE) _deploy-app-of-apps CLUSTER_LABEL=$$CLUSTER_LABEL
	@echo "âœ… Step 3 Complete: ArgoCD installed via Helm with App-of-Apps pattern for $$CLUSTER_LABEL"

_register-cluster-with-argocd: ## Register current cluster with ArgoCD with proper labels
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸ”— Registering cluster 'dv-$$CLUSTER_LABEL' with ArgoCD..." && \
	if ! kubectl get secret cluster-info -n default >/dev/null 2>&1; then \
		echo "ğŸ·ï¸  Creating missing cluster-info secret..."; \
		kubectl create secret generic cluster-info \
			--from-literal=environment=$$CLUSTER_LABEL \
			--from-literal=cluster-name=dv-$$CLUSTER_LABEL \
			-n default; \
	fi && \
	kubectl create secret generic argocd-cluster-local -n argocd \
		--from-literal=name=in-cluster \
		--from-literal=server=https://kubernetes.default.svc \
		--from-literal=config='{"tlsClientConfig":{"insecure":true}}' \
		--dry-run=client -o yaml | kubectl apply -f - && \
	kubectl label secret argocd-cluster-local -n argocd \
		argocd.argoproj.io/secret-type=cluster \
		environment=$$CLUSTER_LABEL \
		--overwrite && \
	echo "âœ… Cluster registration completed"

_setup-argocd-password: ## Setup custom ArgoCD password from .env using kubectl
	@echo "ğŸ”‘ Configuring custom ArgoCD password..."
	@INITIAL_PASSWORD=$$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" | base64 -d) && \
	CUSTOM_PASSWORD=$$(grep ARGOCD_ADMIN_PASSWORD_DEV .env 2>/dev/null | cut -d'=' -f2 || echo "") && \
	if [ -z "$$CUSTOM_PASSWORD" ]; then \
		echo "âš ï¸  ARGOCD_ADMIN_PASSWORD_DEV not found in .env, using initial password"; \
		echo "$$INITIAL_PASSWORD" > .argocd-admin-password; \
		echo "   Initial password saved to: .argocd-admin-password"; \
	else \
		echo "ğŸ”„ Setting custom password from .env using kubectl..."; \
		if ! python3 -c "import bcrypt" >/dev/null 2>&1; then \
			echo "ğŸ“¦ Installing bcrypt for password hashing..."; \
			pip3 install bcrypt --break-system-packages >/dev/null 2>&1 || pip3 install bcrypt >/dev/null 2>&1; \
		fi && \
		BCRYPT_HASH=$$(python3 -c "import bcrypt; print(bcrypt.hashpw(b'$$CUSTOM_PASSWORD', bcrypt.gensalt()).decode('utf-8'))") && \
		kubectl patch secret argocd-secret -n argocd --type='merge' -p="{\"data\":{\"admin.password\":\"$$(echo -n "$$BCRYPT_HASH" | base64 -w0)\"}}" && \
		kubectl delete secret argocd-initial-admin-secret -n argocd --ignore-not-found=true && \
		echo "$$CUSTOM_PASSWORD" > .argocd-admin-password && \
		echo "âœ… Custom password configured and saved to: .argocd-admin-password"; \
	fi

_deploy-app-of-apps: ## Deploy App-of-Apps root Application for ApplicationSets
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸš€ Deploying root Application for ApplicationSets in '$$CLUSTER_LABEL' environment..." && \
	echo "â³ Waiting for ArgoCD to be fully ready... ($$(date '+%H:%M:%S'))" && \
	sleep 10 && \
	if ! kubectl apply -f k8s/argocd/root-applicationsets-$$CLUSTER_LABEL.yaml; then \
		echo "âŒ FAILED: Could not deploy root Application at $$(date '+%H:%M:%S')" && \
		echo "ğŸ’¡ Check file: k8s/argocd/root-applicationsets-$$CLUSTER_LABEL.yaml" && \
		exit 1; \
	fi && \
	echo "â³ Waiting for root Application to be synced... ($$(date '+%H:%M:%S'))" && \
	TIMEOUT=300 && START_TIME=$$(date +%s) && \
	while ! kubectl get application root-applicationsets-$$CLUSTER_LABEL -n argocd -o jsonpath='{.status.sync.status}' 2>/dev/null | grep -q "Synced"; do \
		CURRENT_TIME=$$(date +%s) && \
		if [ $$((CURRENT_TIME - START_TIME)) -gt $$TIMEOUT ]; then \
			echo "âŒ FAILED: Root Application not synced within 5 minutes at $$(date '+%H:%M:%S')" && \
			echo "ğŸ’¡ Check Application status: kubectl get application root-applicationsets-$$CLUSTER_LABEL -n argocd" && \
			exit 1; \
		fi && \
		echo "ğŸ”„ Waiting for Application sync... ($$((CURRENT_TIME - START_TIME))s elapsed)" && \
		sleep 5; \
	done && \
	echo "âœ… Root Application deployed and synced successfully" && \
	echo "ğŸ” ApplicationSets that will be deployed:" && \
	kubectl get applicationsets -n argocd --no-headers 2>/dev/null | grep "$$CLUSTER_LABEL" | awk '{print "  - " $$1}' || echo "  (ApplicationSets will appear shortly)" && \
	echo "ğŸ’¡ Monitor ApplicationSets: kubectl get applicationsets -n argocd"

argocd-password: ## Get ArgoCD admin password
sealed-secrets-create: ## Step 4: Create tunnel token sealed secret from environment file (usage: make sealed-secrets-create CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸš€ Step 4: Creating tunnel token sealed secret for '$$CLUSTER_LABEL'..." && \
	echo "ğŸ” Loading tunnel token from environment file..." && \
	if [ ! -f ".tunnel-token-$$CLUSTER_LABEL" ]; then \
		echo "âŒ Could not find tunnel token file: .tunnel-token-$$CLUSTER_LABEL"; \
		echo "ğŸ’¡ Ensure tunnel verification has been run: make tunnel-verify CLUSTER_LABEL=$$CLUSTER_LABEL"; \
		exit 1; \
	fi && \
	TUNNEL_TOKEN=$$(grep "TUNNEL_TOKEN_$$CLUSTER_LABEL" .tunnel-token-$$CLUSTER_LABEL | cut -d'=' -f2) && \
	if [ -z "$$TUNNEL_TOKEN" ]; then \
		echo "âŒ Could not extract tunnel token from environment file"; \
		echo "ğŸ’¡ Ensure tunnel verification has been run: make tunnel-verify CLUSTER_LABEL=$$CLUSTER_LABEL"; \
		exit 1; \
	fi && \
	echo "âœ… Loaded tunnel token from environment file" && \
	echo "ğŸ” Extracting tunnel ID for logging..." && \
	TUNNEL_INFO=$$(echo "$$TUNNEL_TOKEN" | base64 -d) && \
	TUNNEL_ID=$$(echo "$$TUNNEL_INFO" | jq -r '.t // "unknown"') && \
	echo "âœ… Tunnel ID: $$TUNNEL_ID" && \
	echo "âœ… Tunnel token loaded: $$(echo "$$TUNNEL_TOKEN" | cut -c1-20)..." && \
	kubectl config use-context do-nyc2-dv-$$CLUSTER_LABEL && \
	echo "ğŸ”§ Installing kubeseal CLI if needed..." && \
	$(MAKE) _install-kubeseal && \
	echo "â³ Waiting for sealed-secrets controller to be ready..." && \
	kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=sealed-secrets -n kube-system --timeout=300s && \
	echo "ğŸ” Creating sealed secret from tunnel token..." && \
	echo -n "$$TUNNEL_TOKEN" | kubectl create secret generic cloudflared-token \
		--dry-run=client --from-file=tunnel-token=/dev/stdin \
		--namespace=cloudflare-tunnel-$$CLUSTER_LABEL -o yaml | \
	kubeseal -o yaml --namespace=cloudflare-tunnel-$$CLUSTER_LABEL > \
		k8s/infrastructure/cloudflare-tunnel/environments/$$CLUSTER_LABEL/cloudflared-token-sealedsecret.yaml && \
	echo "ğŸ”§ Updating kustomization to include sealed secret..." && \
	$(MAKE) _update-kustomization-for-sealed-secret CLUSTER_LABEL=$$CLUSTER_LABEL && \
	echo "ğŸ’¾ Committing sealed secret to repository..." && \
	git add k8s/infrastructure/cloudflare-tunnel/environments/$$CLUSTER_LABEL/ && \
	git commit -m "Add tunnel token sealed secret for cloudflare-tunnel-$$CLUSTER_LABEL (tunnel: $$TUNNEL_ID)" && \
	git push && \
	echo "â³ Waiting for tunnel application to sync and become healthy..." && \
	sleep 30 && \
	echo "âœ… Step 5 Complete: Tunnel token sealed secret created for $$CLUSTER_LABEL (tunnel: $$TUNNEL_ID)"

argocd-verify: ## Step 6: Verify ArgoCD server is accessible at its URL (usage: make argocd-verify CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸš€ Step 6: Verifying ArgoCD server accessibility for '$$CLUSTER_LABEL'..." && \
	kubectl config use-context do-nyc2-dv-$$CLUSTER_LABEL && \
	echo "ğŸ” Checking ArgoCD server pod status..." && \
	if ! kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=argocd-server -n argocd --timeout=60s; then \
		echo "âŒ FAILED: ArgoCD server pod not ready at $$(date '+%H:%M:%S')" && \
		echo "ğŸ’¡ Check pods: kubectl get pods -n argocd" && \
		exit 1; \
	fi && \
	ARGOCD_URL="https://$$CLUSTER_LABEL.argocd.diocesanvitality.org" && \
	echo "ğŸŒ Testing ArgoCD URL: $$ARGOCD_URL" && \
	echo "ğŸŒ Testing ArgoCD login screen (30 second timeout)..." && \
	TIMEOUT=30 && START_TIME=$$(date +%s) && \
	ARGOCD_ACCESSIBLE=false && \
	while true; do \
		RESPONSE=$$(curl -k -s --connect-timeout 5 --max-time 10 "$$ARGOCD_URL" 2>/dev/null || echo "") && \
		if echo "$$RESPONSE" | grep -q "Argo CD" && echo "$$RESPONSE" | grep -q "html"; then \
			echo "âœ… ArgoCD login screen confirmed at $$ARGOCD_URL"; \
			ARGOCD_ACCESSIBLE=true && \
			break; \
		elif [ -n "$$RESPONSE" ]; then \
			echo "ğŸ” URL responding but not ArgoCD login screen - checking content..." && \
			if echo "$$RESPONSE" | grep -qi "error\|not found\|503\|502\|500"; then \
				echo "âš ï¸  Server error detected in response"; \
			else \
				echo "âš ï¸  Unexpected response content (not ArgoCD login)"; \
			fi; \
		fi && \
		CURRENT_TIME=$$(date +%s) && \
		if [ $$((CURRENT_TIME - START_TIME)) -gt $$TIMEOUT ]; then \
			echo "âš ï¸  ArgoCD login screen not accessible within 30 seconds" && \
			if [ -n "$$RESPONSE" ]; then \
				echo "ğŸ’¡ URL is responding but not showing ArgoCD login screen" && \
				echo "ğŸ’¡ Check tunnel configuration and ArgoCD server status"; \
			else \
				echo "ğŸ’¡ URL not responding - DNS/tunnel may need more time to propagate" && \
				echo "ğŸ’¡ Try accessing $$ARGOCD_URL manually in a few minutes"; \
			fi && \
			echo "ğŸ’¡ Check tunnel status: kubectl get pods -n cloudflare-tunnel-$$CLUSTER_LABEL" && \
			break; \
		fi && \
		echo "ğŸ”„ Waiting for ArgoCD login screen... ($$((CURRENT_TIME - START_TIME))s elapsed)" && \
		sleep 5; \
	done && \
	if [ "$$ARGOCD_ACCESSIBLE" = "true" ]; then \
		echo "ğŸ” ArgoCD login screen verified successfully"; \
	else \
		echo "âš ï¸  ArgoCD login screen verification incomplete - manual check recommended"; \
	fi && \
	echo "ğŸ”‘ ArgoCD Login Information:" && \
	echo "   URL: $$ARGOCD_URL" && \
	echo "   Username: admin" && \
	if [ -f .argocd-admin-password ]; then \
		echo "   Password: $$(cat .argocd-admin-password)"; \
	else \
		echo "   Password: $$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath='{.data.password}' | base64 -d)"; \
	fi && \
	echo "âœ… Step 6 Complete: ArgoCD server verified and accessible at $$ARGOCD_URL"

docker-build: ## Step 6.5: Build and push Docker images from appropriate branch (usage: make docker-build CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸš€ Step 6.5: Building and pushing Docker images for '$$CLUSTER_LABEL'..." && \
	echo "ğŸ¯ Setting source branch for $$CLUSTER_LABEL environment..." && \
	if [ "$$CLUSTER_LABEL" = "dev" ]; then \
		SOURCE_BRANCH="develop"; \
	elif [ "$$CLUSTER_LABEL" = "stg" ]; then \
		SOURCE_BRANCH="staging"; \
	else \
		SOURCE_BRANCH="main"; \
	fi && \
	echo "ğŸ“‹ Docker build configuration:" && \
	echo "   Environment: $$CLUSTER_LABEL" && \
	echo "   Source branch: $$SOURCE_BRANCH" && \
	echo "   Registry: Docker Hub (tomatl/diocesan-vitality)" && \
	echo "ğŸ” Checking current git branch..." && \
	CURRENT_BRANCH=$$(git branch --show-current) && \
	echo "   Current branch: $$CURRENT_BRANCH" && \
	if [ "$$CURRENT_BRANCH" != "$$SOURCE_BRANCH" ]; then \
		echo "ğŸ”„ Switching to $$SOURCE_BRANCH branch..." && \
		git fetch origin && \
		git checkout $$SOURCE_BRANCH && \
		git pull origin $$SOURCE_BRANCH && \
		echo "âœ… Switched to $$SOURCE_BRANCH branch"; \
	else \
		echo "âœ… Already on $$SOURCE_BRANCH branch" && \
		git pull origin $$SOURCE_BRANCH; \
	fi && \
	echo "ğŸ·ï¸  Generating image tags..." && \
	TIMESTAMP=$$(date +%Y-%m-%d-%H-%M-%S) && \
	IMAGE_TAG="$$CLUSTER_LABEL-$$TIMESTAMP" && \
	echo "   Image tag: $$IMAGE_TAG" && \
	echo "ğŸ”§ Checking Docker login..." && \
	if ! docker info >/dev/null 2>&1; then \
		echo "âŒ FAILED: Docker daemon not running at $$(date '+%H:%M:%S')" && \
		echo "ğŸ’¡ Start Docker daemon and ensure you're logged in: docker login" && \
		exit 1; \
	fi && \
	echo "ğŸ—ï¸  Building multi-platform images..." && \
	echo "ğŸ“¦ Building backend image..." && \
	if ! docker buildx build --platform linux/amd64,linux/arm64 \
		-f backend/Dockerfile \
		-t tomatl/diocesan-vitality:backend-$$IMAGE_TAG \
		-t tomatl/diocesan-vitality:backend-$$CLUSTER_LABEL-latest \
		--push backend/; then \
		echo "âŒ FAILED: Backend image build failed at $$(date '+%H:%M:%S')" && \
		exit 1; \
	fi && \
	echo "ğŸ“¦ Building frontend image..." && \
	if ! docker buildx build --platform linux/amd64,linux/arm64 \
		-f frontend/Dockerfile \
		-t tomatl/diocesan-vitality:frontend-$$IMAGE_TAG \
		-t tomatl/diocesan-vitality:frontend-$$CLUSTER_LABEL-latest \
		--push frontend/; then \
		echo "âŒ FAILED: Frontend image build failed at $$(date '+%H:%M:%S')" && \
		exit 1; \
	fi && \
	echo "ğŸ“¦ Building pipeline image..." && \
	if ! docker buildx build --platform linux/amd64,linux/arm64 \
		-f Dockerfile.pipeline \
		-t tomatl/diocesan-vitality:pipeline-$$IMAGE_TAG \
		-t tomatl/diocesan-vitality:pipeline-$$CLUSTER_LABEL-latest \
		--push .; then \
		echo "âŒ FAILED: Pipeline image build failed at $$(date '+%H:%M:%S')" && \
		exit 1; \
	fi && \
	echo "ğŸ¯ Updating Kubernetes manifests with new image tags..." && \
	MANIFEST_PATH="k8s/environments/development" && \
	if [ "$$CLUSTER_LABEL" = "stg" ]; then MANIFEST_PATH="k8s/environments/staging"; \
	elif [ "$$CLUSTER_LABEL" = "prd" ]; then MANIFEST_PATH="k8s/environments/production"; fi && \
	echo "   Manifest path: $$MANIFEST_PATH" && \
	if [ -f "$$MANIFEST_PATH/kustomization.yaml" ]; then \
		echo "ğŸ”„ Updating image tags in Kubernetes manifests..." && \
		if [ -f "$$MANIFEST_PATH/backend-deployment.yaml" ]; then \
			sed -i "s|image: tomatl/diocesan-vitality:backend-.*|image: tomatl/diocesan-vitality:backend-$$IMAGE_TAG|g" "$$MANIFEST_PATH/backend-deployment.yaml"; \
		fi && \
		if [ -f "$$MANIFEST_PATH/frontend-deployment.yaml" ]; then \
			sed -i "s|image: tomatl/diocesan-vitality:frontend-.*|image: tomatl/diocesan-vitality:frontend-$$IMAGE_TAG|g" "$$MANIFEST_PATH/frontend-deployment.yaml"; \
		fi && \
		if [ -f "$$MANIFEST_PATH/pipeline-deployment.yaml" ]; then \
			sed -i "s|image: tomatl/diocesan-vitality:pipeline-.*|image: tomatl/diocesan-vitality:pipeline-$$IMAGE_TAG|g" "$$MANIFEST_PATH/pipeline-deployment.yaml"; \
		fi && \
		echo "ğŸ’¾ Committing image tag updates to git..." && \
		git add $$MANIFEST_PATH/ && \
		git commit -m "Update $$CLUSTER_LABEL environment images to $$IMAGE_TAG" && \
		git push origin $$SOURCE_BRANCH && \
		echo "âœ… Image tags updated and committed to $$SOURCE_BRANCH"; \
	else \
		echo "âš ï¸  Kubernetes manifests not found at $$MANIFEST_PATH" && \
		echo "ğŸ’¡ Images built and pushed, but manifests need manual update"; \
	fi && \
	echo "ğŸ“Š Built images:" && \
	echo "   Backend: tomatl/diocesan-vitality:backend-$$IMAGE_TAG" && \
	echo "   Frontend: tomatl/diocesan-vitality:frontend-$$IMAGE_TAG" && \
	echo "   Pipeline: tomatl/diocesan-vitality:pipeline-$$IMAGE_TAG" && \
	echo "ğŸ’¡ GitOps will automatically deploy these images when ArgoCD syncs" && \
	echo "âœ… Step 6.5 Complete: Docker images built and pushed from $$SOURCE_BRANCH branch"

app-deploy: ## Step 7: Verify diocesan-vitality application deployment via GitOps (usage: make app-deploy CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸš€ Step 7: Verifying diocesan-vitality application deployment for '$$CLUSTER_LABEL'..." && \
	kubectl config use-context do-nyc2-dv-$$CLUSTER_LABEL && \
	echo "ğŸ” Checking that ArgoCD ApplicationSets are ready..." && \
	if ! kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=argocd-server -n argocd --timeout=30s; then \
		echo "âŒ FAILED: ArgoCD not ready at $$(date '+%H:%M:%S')" && \
		echo "ğŸ’¡ Run: make argocd-verify CLUSTER_LABEL=$$CLUSTER_LABEL" && \
		exit 1; \
	fi && \
	echo "ğŸ¯ GitOps configuration for $$CLUSTER_LABEL environment:" && \
	if [ "$$CLUSTER_LABEL" = "dev" ]; then \
		TARGET_BRANCH="develop"; \
		echo "   Source branch: $$TARGET_BRANCH (configured in ApplicationSet)"; \
	elif [ "$$CLUSTER_LABEL" = "stg" ]; then \
		TARGET_BRANCH="staging"; \
		echo "   Source branch: $$TARGET_BRANCH (configured in ApplicationSet)"; \
	else \
		TARGET_BRANCH="main"; \
		echo "   Source branch: $$TARGET_BRANCH (configured in ApplicationSet)"; \
	fi && \
	echo "   Application: diocesan-vitality-$$CLUSTER_LABEL" && \
	echo "   Namespace: diocesan-vitality-$$CLUSTER_LABEL" && \
	echo "ğŸ”„ Checking current application status..." && \
	if ! kubectl get application diocesan-vitality-$$CLUSTER_LABEL -n argocd >/dev/null 2>&1; then \
		echo "âŒ FAILED: diocesan-vitality-$$CLUSTER_LABEL application not found at $$(date '+%H:%M:%S')" && \
		echo "ğŸ’¡ Ensure ArgoCD ApplicationSets are deployed: kubectl get applicationsets -n argocd" && \
		echo "ğŸ’¡ Check App-of-Apps root: kubectl get application root-applicationsets-$$CLUSTER_LABEL -n argocd" && \
		exit 1; \
	fi && \
	CURRENT_STATUS=$$(kubectl get application diocesan-vitality-$$CLUSTER_LABEL -n argocd -o jsonpath='{.status.sync.status}' 2>/dev/null || echo "Unknown") && \
	CURRENT_HEALTH=$$(kubectl get application diocesan-vitality-$$CLUSTER_LABEL -n argocd -o jsonpath='{.status.health.status}' 2>/dev/null || echo "Unknown") && \
	CURRENT_BRANCH=$$(kubectl get application diocesan-vitality-$$CLUSTER_LABEL -n argocd -o jsonpath='{.spec.source.targetRevision}' 2>/dev/null || echo "Unknown") && \
	echo "   Current sync status: $$CURRENT_STATUS" && \
	echo "   Current health: $$CURRENT_HEALTH" && \
	echo "   Current branch: $$CURRENT_BRANCH" && \
	if [ "$$CURRENT_BRANCH" != "$$TARGET_BRANCH" ]; then \
		echo "âš ï¸  Application is configured for branch '$$CURRENT_BRANCH' but should be '$$TARGET_BRANCH'" && \
		echo "ğŸ’¡ Check ApplicationSet configuration: k8s/argocd/diocesan-vitality-$$CLUSTER_LABEL-applicationset.yaml"; \
	fi && \
	echo "â³ Monitoring application sync status (up to 2 minutes)..." && \
	TIMEOUT=120 && START_TIME=$$(date +%s) && \
	while true; do \
		SYNC_STATUS=$$(kubectl get application diocesan-vitality-$$CLUSTER_LABEL -n argocd -o jsonpath='{.status.sync.status}' 2>/dev/null || echo "Unknown") && \
		HEALTH_STATUS=$$(kubectl get application diocesan-vitality-$$CLUSTER_LABEL -n argocd -o jsonpath='{.status.health.status}' 2>/dev/null || echo "Unknown") && \
		if [ "$$SYNC_STATUS" = "Synced" ] && [ "$$HEALTH_STATUS" = "Healthy" ]; then \
			echo "âœ… Application successfully synced and healthy via GitOps"; \
			break; \
		elif [ "$$SYNC_STATUS" = "Synced" ] && [ "$$HEALTH_STATUS" != "Healthy" ]; then \
			echo "âš ï¸  Application synced but not healthy: $$HEALTH_STATUS"; \
			echo "ğŸ’¡ This may be normal if container images are not yet available"; \
			break; \
		fi && \
		CURRENT_TIME=$$(date +%s) && \
		if [ $$((CURRENT_TIME - START_TIME)) -gt $$TIMEOUT ]; then \
			echo "â³ Application still syncing after 2 minutes" && \
			echo "ğŸ’¡ Current status: Sync=$$SYNC_STATUS, Health=$$HEALTH_STATUS" && \
			echo "ğŸ’¡ GitOps deployments may take time for initial sync" && \
			break; \
		fi && \
		echo "ğŸ”„ Waiting for GitOps sync... Sync=$$SYNC_STATUS, Health=$$HEALTH_STATUS ($$((CURRENT_TIME - START_TIME))s elapsed)" && \
		sleep 10; \
	done && \
	echo "ğŸ“Š Final deployment status:" && \
	kubectl get application diocesan-vitality-$$CLUSTER_LABEL -n argocd -o custom-columns=NAME:.metadata.name,SYNC:.status.sync.status,HEALTH:.status.health.status,BRANCH:.spec.source.targetRevision,REVISION:.status.sync.revision && \
	echo "ğŸŒ Application URLs (when healthy):" && \
	echo "   Frontend: https://$$CLUSTER_LABEL.ui.diocesanvitality.org" && \
	echo "   Backend API: https://$$CLUSTER_LABEL.api.diocesanvitality.org" && \
	echo "ğŸ’¡ Monitor deployment: kubectl get pods -n diocesan-vitality-$$CLUSTER_LABEL" && \
	echo "ğŸ’¡ GitOps approach: Application configured via ApplicationSet to deploy from $$TARGET_BRANCH branch" && \
	echo "âœ… Step 7 Complete: diocesan-vitality application verified via GitOps"

_install-helm: ## Install Helm CLI if not present
	@if ! command -v helm >/dev/null 2>&1; then \
		echo "ğŸ“¦ Installing Helm CLI..."; \
		curl -fsSL -o /tmp/get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 && \
		chmod 700 /tmp/get_helm.sh && \
		/tmp/get_helm.sh && \
		rm -f /tmp/get_helm.sh && \
		echo "âœ… Helm CLI installed successfully"; \
	else \
		echo "âœ… Helm CLI already installed"; \
	fi

_install-kubeseal: ## Install kubeseal CLI if not present
	@if ! command -v kubeseal >/dev/null 2>&1; then \
		echo "ğŸ“¦ Installing kubeseal CLI..."; \
		KUBESEAL_VERSION=$$(curl -s "https://api.github.com/repos/bitnami-labs/sealed-secrets/releases/latest" | grep -Po '"tag_name": "v\K[^"]*'); \
		ARCH=$$(uname -m); \
		case $$ARCH in \
			x86_64) ARCH="amd64" ;; \
			aarch64) ARCH="arm64" ;; \
			armv7l) ARCH="arm" ;; \
		esac && \
		wget -q "https://github.com/bitnami-labs/sealed-secrets/releases/latest/download/kubeseal-$${KUBESEAL_VERSION}-linux-$${ARCH}.tar.gz" -O /tmp/kubeseal.tar.gz && \
		tar -xzf /tmp/kubeseal.tar.gz -C /tmp && \
		sudo mv /tmp/kubeseal /usr/local/bin/ && \
		sudo chmod +x /usr/local/bin/kubeseal && \
		rm -f /tmp/kubeseal.tar.gz && \
		echo "âœ… kubeseal CLI installed successfully"; \
	else \
		echo "âœ… kubeseal CLI already installed"; \
	fi
	@echo "ğŸ”‘ ArgoCD Admin Password:"
	@if [ -f .argocd-admin-password ]; then \
		cat .argocd-admin-password && echo; \
	else \
		kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath="{.data.password}" 2>/dev/null | base64 -d && echo || echo "âŒ ArgoCD not installed or password not found"; \
	fi

_update-kustomization-for-sealed-secret: ## Update kustomization.yaml to include sealed secret
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	KUSTOMIZATION_FILE="k8s/infrastructure/cloudflare-tunnel/environments/$$CLUSTER_LABEL/kustomization.yaml" && \
	SEALED_SECRET_FILE="cloudflared-token-sealedsecret.yaml" && \
	echo "ğŸ”§ Checking kustomization file: $$KUSTOMIZATION_FILE" && \
	if ! grep -q "$$SEALED_SECRET_FILE" "$$KUSTOMIZATION_FILE"; then \
		echo "ğŸ“ Adding sealed secret to kustomization resources..." && \
		sed -i "/resources:/a\  - $$SEALED_SECRET_FILE" "$$KUSTOMIZATION_FILE"; \
	else \
		echo "âœ… Sealed secret already included in kustomization"; \
	fi

infra-status: ## Check infrastructure status
	@echo "ğŸ” Infrastructure Status:"
	@echo "========================"
	@echo "Kubectl contexts:"
	@kubectl config get-contexts | grep -E "(CURRENT|do-nyc2)" || echo "  No dev contexts found"
	@echo ""
	@echo "ArgoCD status:"
	@kubectl get pods -n argocd 2>/dev/null | grep -E "(NAME|argocd-server)" || echo "  ArgoCD not installed"
	@echo ""
	@echo "Applications:"
	@kubectl get applications -n argocd 2>/dev/null || echo "  No applications found"
	@echo ""
	@echo "Tunnel status:"
	@cd terraform/environments/dev && terraform output tunnel_info 2>/dev/null || echo "  No tunnel found"

infra-destroy: ## Destroy complete infrastructure (usage: make infra-destroy CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸ§¹ Destroying infrastructure for '$$CLUSTER_LABEL'..." && \
	$(MAKE) tunnel-destroy CLUSTER_LABEL=$$CLUSTER_LABEL && \
	$(MAKE) argocd-destroy CLUSTER_LABEL=$$CLUSTER_LABEL && \
	$(MAKE) cluster-destroy CLUSTER_LABEL=$$CLUSTER_LABEL && \
	echo "âœ… Infrastructure destroyed for $$CLUSTER_LABEL"

tunnel-destroy: ## Destroy Cloudflare tunnel (usage: make tunnel-destroy CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸ§¹ Destroying Cloudflare tunnel for '$$CLUSTER_LABEL'..." && \
	if [ "$$CLUSTER_LABEL" = "stg" ]; then ENV_DIR="staging"; else ENV_DIR="$$CLUSTER_LABEL"; fi && \
	cd terraform/environments/$$ENV_DIR && \
		export CLOUDFLARE_API_TOKEN=$$(grep CLOUDFLARE_API_TOKEN ../../../.env | cut -d'=' -f2) && \
		terraform destroy -target=module.cloudflare_tunnel -auto-approve || true && \
		terraform state list | grep "module.cloudflare_tunnel" | xargs -r terraform state rm || true

argocd-destroy: ## Destroy ArgoCD (usage: make argocd-destroy CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸ§¹ Destroying ArgoCD for '$$CLUSTER_LABEL'..." && \
	kubectl config use-context do-nyc2-dv-$$CLUSTER_LABEL && \
	echo "ğŸ”§ Removing finalizers from ArgoCD applications..." && \
	kubectl get applications -n argocd -o name 2>/dev/null | xargs -r -I {} kubectl patch {} -n argocd --type='merge' -p='{"metadata":{"finalizers":null}}' || true && \
	echo "ğŸ—‘ï¸  Deleting ArgoCD namespace..." && \
	kubectl delete namespace argocd --ignore-not-found=true

cluster-destroy: ## Destroy cluster (usage: make cluster-destroy CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸ§¹ Destroying cluster for '$$CLUSTER_LABEL'..." && \
	if [ "$$CLUSTER_LABEL" = "stg" ]; then ENV_DIR="staging"; else ENV_DIR="$$CLUSTER_LABEL"; fi && \
	cd terraform/environments/$$ENV_DIR && \
		export DIGITALOCEAN_TOKEN=$$(grep DIGITALOCEAN_TOKEN ../../../.env | cut -d'=' -f2) && \
		terraform destroy -target=module.k8s_cluster -auto-approve || true

tunnel-verify: ## Step 2.5: Verify tunnel and cluster, save tunnel token to environment (usage: make tunnel-verify CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸ” Step 2.5: Verifying tunnel and cluster for '$$CLUSTER_LABEL'..." && \
	if [ "$$CLUSTER_LABEL" = "stg" ]; then ENV_DIR="staging"; else ENV_DIR="$$CLUSTER_LABEL"; fi && \
	echo "ğŸ“‹ Verifying cluster status... ($$(date '+%H:%M:%S'))" && \
	if ! kubectl config use-context do-nyc2-dv-$$CLUSTER_LABEL; then \
		echo "âŒ FAILED: Could not switch to kubectl context do-nyc2-dv-$$CLUSTER_LABEL at $$(date '+%H:%M:%S')" && \
		echo "ğŸ’¡ Check if cluster exists: doctl kubernetes cluster list" && \
		exit 1; \
	fi && \
	if ! kubectl get nodes --no-headers | wc -l | grep -q "[1-9]"; then \
		echo "âŒ FAILED: Cluster has no ready nodes at $$(date '+%H:%M:%S')" && \
		echo "ğŸ’¡ Check cluster status: kubectl get nodes" && \
		exit 1; \
	fi && \
	echo "âœ… Cluster verification passed ($$(date '+%H:%M:%S'))" && \
	echo "ğŸ” Verifying tunnel creation... ($$(date '+%H:%M:%S'))" && \
	cd terraform/environments/$$ENV_DIR && \
		export $$(grep CLOUDFLARE_API_TOKEN ../../../.env | xargs) && \
		if ! TUNNEL_OUTPUT=$$(terraform output -json tunnel_info 2>/dev/null); then \
			echo "âŒ FAILED: Could not get tunnel info from Terraform at $$(date '+%H:%M:%S')" && \
			echo "ğŸ’¡ Check if tunnel was created: make tunnel-create CLUSTER_LABEL=$$CLUSTER_LABEL" && \
			exit 1; \
		fi && \
		TUNNEL_ID=$$(echo "$$TUNNEL_OUTPUT" | jq -r '.id // empty') && \
		TUNNEL_CNAME=$$(echo "$$TUNNEL_OUTPUT" | jq -r '.cname // empty') && \
		if [ -z "$$TUNNEL_ID" ] || [ -z "$$TUNNEL_CNAME" ]; then \
			echo "âŒ FAILED: Tunnel verification failed - missing tunnel info at $$(date '+%H:%M:%S')" && \
			echo "ğŸ’¡ Tunnel output: $$TUNNEL_OUTPUT" && \
			exit 1; \
		fi && \
		echo "âœ… Tunnel verification passed: $$TUNNEL_ID ($$(date '+%H:%M:%S'))" && \
		echo "ğŸ” Extracting tunnel token from k8s-secrets... ($$(date '+%H:%M:%S'))" && \
		CREDENTIALS_FILE="k8s-secrets/cloudflare-tunnel-$$ENV_DIR.yaml" && \
		if [ ! -f "$$CREDENTIALS_FILE" ]; then \
			echo "âŒ FAILED: Could not find tunnel credentials file: $$CREDENTIALS_FILE at $$(date '+%H:%M:%S')" && \
			echo "ğŸ’¡ Check if tunnel created credentials: ls -la terraform/environments/$$ENV_DIR/k8s-secrets/" && \
			exit 1; \
		fi && \
		if ! CREDENTIALS_B64=$$(grep "credentials.json" "$$CREDENTIALS_FILE" | cut -d'"' -f4); then \
			echo "âŒ FAILED: Could not extract credentials from file at $$(date '+%H:%M:%S')" && \
			echo "ğŸ’¡ Check file format: head -5 $$CREDENTIALS_FILE" && \
			exit 1; \
		fi && \
		if ! CREDENTIALS_JSON=$$(echo "$$CREDENTIALS_B64" | base64 -d 2>/dev/null); then \
			echo "âŒ FAILED: Could not decode base64 credentials at $$(date '+%H:%M:%S')" && \
			exit 1; \
		fi && \
		ACCOUNT_TAG=$$(echo "$$CREDENTIALS_JSON" | jq -r '.AccountTag') && \
		TUNNEL_SECRET=$$(echo "$$CREDENTIALS_JSON" | jq -r '.TunnelSecret') && \
		if [ -z "$$ACCOUNT_TAG" ] || [ -z "$$TUNNEL_SECRET" ]; then \
			echo "âŒ FAILED: Missing AccountTag or TunnelSecret at $$(date '+%H:%M:%S')" && \
			echo "ğŸ’¡ Credentials JSON: $$CREDENTIALS_JSON" && \
			exit 1; \
		fi && \
		TUNNEL_SECRET_B64=$$(echo -n "$$TUNNEL_SECRET" | base64 -w0) && \
		TUNNEL_TOKEN=$$(echo "{\"a\":\"$$ACCOUNT_TAG\",\"t\":\"$$TUNNEL_ID\",\"s\":\"$$TUNNEL_SECRET_B64\"}" | base64 -w0) && \
		if [ -z "$$TUNNEL_TOKEN" ]; then \
			echo "âŒ FAILED: Failed to generate tunnel token at $$(date '+%H:%M:%S')" && \
			exit 1; \
		fi && \
		echo "ğŸ’¾ Saving tunnel token to environment file... ($$(date '+%H:%M:%S'))" && \
		echo "TUNNEL_TOKEN_$$CLUSTER_LABEL=$$TUNNEL_TOKEN" > ../../../.tunnel-token-$$CLUSTER_LABEL && \
		echo "âœ… Tunnel token saved to .tunnel-token-$$CLUSTER_LABEL" && \
		echo "ğŸ” Verifying token format... ($$(date '+%H:%M:%S'))" && \
		if ! echo "$$TUNNEL_TOKEN" | base64 -d | jq . >/dev/null 2>&1; then \
			echo "âŒ FAILED: Token format verification failed at $$(date '+%H:%M:%S')" && \
			exit 1; \
		fi && \
		echo "âœ… Tunnel token verification passed ($$(date '+%H:%M:%S'))"
	@echo "âœ… Step 2.5 Complete: Tunnel and cluster verified, token saved"

infra-test: ## Step 6: Integration testing and cleanup (usage: make infra-test CLUSTER_LABEL=dev)
	@CLUSTER_LABEL=$${CLUSTER_LABEL:-dev} && \
	echo "ğŸ§ª Step 6: Running integration tests and cleanup for '$$CLUSTER_LABEL'..." && \
	echo "ğŸ” Testing cluster connectivity..." && \
	kubectl config use-context do-nyc2-dv-$$CLUSTER_LABEL && \
	kubectl get nodes >/dev/null && \
	echo "âœ… Cluster connectivity test passed" && \
	echo "ğŸ” Testing ArgoCD installation..." && \
	kubectl get pods -n argocd | grep -q "argocd-server.*Running" && \
	echo "âœ… ArgoCD installation test passed" && \
	echo "ğŸ” Testing ApplicationSets..." && \
	kubectl get applicationsets -n argocd | grep -q "diocesan-vitality-$$CLUSTER_LABEL" && \
	echo "âœ… ApplicationSets test passed" && \
	echo "ğŸ” Testing sealed-secrets controller..." && \
	kubectl get pods -n kube-system -l app.kubernetes.io/name=sealed-secrets | grep -q "Running" && \
	echo "âœ… Sealed-secrets controller test passed" && \
	echo "ğŸ§¹ Cleaning up temporary files..." && \
	rm -f .tunnel-token-$$CLUSTER_LABEL && \
	echo "âœ… Temporary tunnel token file removed" && \
	echo "ğŸ” Verifying no sensitive data in environment..." && \
	if env | grep -q "TUNNEL_TOKEN"; then \
		echo "âš ï¸  Found tunnel tokens in environment - consider unsetting them"; \
	else \
		echo "âœ… No tunnel tokens found in environment"; \
	fi && \
	echo "ğŸ“Š Final infrastructure status:" && \
	$(MAKE) infra-status CLUSTER_LABEL=$$CLUSTER_LABEL
	@echo "âœ… Step 6 Complete: Integration tests passed and cleanup completed"
