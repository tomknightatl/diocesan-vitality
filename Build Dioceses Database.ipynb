{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdebixheGT9gyz8u1b9Lpy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomknightatl/USCCB/blob/main/Build%20Dioceses%20Database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pip-install-supabase-cell"
      },
      "outputs": [],
      "source": [
        "!pip install supabase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "supabase-init-cell"
      },
      "outputs": [],
      "source": [
        "# Cell for Supabase client initialization\n",
        "from supabase import create_client, Client\n",
        "import os\n",
        "\n",
        "# IMPORTANT: Replace with your actual Supabase URL and Key\n",
        "# It's recommended to use environment variables or a secure way to manage credentials.\n",
        "# For demonstration, placeholders are used here.\n",
        "# You can set these as environment variables in your Colab environment (e.g., using os.environ)\n",
        "# or directly replace the strings below if you are running this in a secure, private environment.\n",
        "\n",
        "SUPABASE_URL = \"YOUR_SUPABASE_URL\"  # Replace with your Supabase project URL\n",
        "SUPABASE_KEY = \"YOUR_SUPABASE_ANON_KEY\" # Replace with your Supabase anon key\n",
        "\n",
        "# Attempt to get from environment variables if set, otherwise use placeholders\n",
        "supabase_url = os.environ.get(\"SUPABASE_URL\", SUPABASE_URL)\n",
        "supabase_key = os.environ.get(\"SUPABASE_KEY\", SUPABASE_KEY)\n",
        "\n",
        "if supabase_url == \"YOUR_SUPABASE_URL\" or supabase_key == \"YOUR_SUPABASE_ANON_KEY\":\n",
        "    print(\"WARNING: Supabase URL or Key is using placeholder values.\")\n",
        "    print(\"Please replace 'YOUR_SUPABASE_URL' and 'YOUR_SUPABASE_ANON_KEY' in this cell with your actual Supabase credentials.\")\n",
        "    print(\"Alternatively, set them as environment variables SUPABASE_URL and SUPABASE_KEY.\")\n",
        "    # Initialize with placeholders, a connection attempt might fail if these are not valid\n",
        "    # Or, you might choose to raise an error or prevent client creation until they are set.\n",
        "    # For now, we'll allow initialization to proceed to show the structure.\n",
        "    supabase: Client = create_client(supabase_url, supabase_key)\n",
        "    print(\"Supabase client initialized with placeholder credentials (likely non-functional).\")\n",
        "else:\n",
        "    try:\n",
        "        supabase: Client = create_client(supabase_url, supabase_key)\n",
        "        print(\"Successfully initialized Supabase client.\")\n",
        "        # Optional: You could add a small test here, like listing tables if permissions allow,\n",
        "        # but for now, just initialization is fine.\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Supabase client: {e}\")\n",
        "        print(\"Please ensure your SUPABASE_URL and SUPABASE_KEY are correct.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhF7zOWbH9fN"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Import necessary libraries\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from urllib.parse import urljoin, urlparse\n",
        "import time\n",
        "import logging\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"scraping.log\"),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Define helper functions\n",
        "\n",
        "def get_soup(url, retries=3, backoff_factor=1.0):\n",
        "    \"\"\"\n",
        "    Fetches the content at the given URL and returns a BeautifulSoup object.\n",
        "    Implements retries with exponential backoff in case of request failures.\n",
        "    \"\"\"\n",
        "    headers = {\n",
        "        'User-Agent': ('Mozilla/5.0 (Windows NT 10.0; Win64; x64) '\n",
        "                       'AppleWebKit/537.36 (KHTML, like Gecko) '\n",
        "                       'Chrome/58.0.3029.110 Safari/537.3'),\n",
        "        'Accept-Language': 'en-US,en;q=0.9',\n",
        "        'Accept-Encoding': 'gzip, deflate',\n",
        "        'Connection': 'keep-alive'\n",
        "    }\n",
        "\n",
        "    for attempt in range(1, retries + 1):\n",
        "        try:\n",
        "            logging.info(f\"Attempt {attempt}: Fetching URL: {url}\")\n",
        "            response = requests.get(url, headers=headers, timeout=20)\n",
        "            logging.info(f\"Received status code: {response.status_code}\")\n",
        "            response.raise_for_status()\n",
        "            return BeautifulSoup(response.text, 'html.parser')\n",
        "        except requests.RequestException as e:\n",
        "            logging.warning(f\"Attempt {attempt} failed with error: {e}\")\n",
        "            if attempt == retries:\n",
        "                logging.error(f\"All {retries} attempts failed for URL: {url}\")\n",
        "                return None\n",
        "            sleep_time = backoff_factor * (2 ** (attempt - 1))\n",
        "            logging.info(f\"Retrying in {sleep_time} seconds...\")\n",
        "            time.sleep(sleep_time)\n",
        "\n",
        "def extract_dioceses(soup):\n",
        "    \"\"\"\n",
        "    Extracts dioceses information from the parsed HTML.\n",
        "    Returns a list of dictionaries with diocese details.\n",
        "    \"\"\"\n",
        "    dioceses = []\n",
        "    diocese_containers = soup.find_all('div', class_='views-row')\n",
        "\n",
        "    logging.info(f\"Found {len(diocese_containers)} potential diocese containers\")\n",
        "\n",
        "    for i, container in enumerate(diocese_containers):\n",
        "        logging.info(f\"Processing container {i+1}\")\n",
        "\n",
        "        da_wrap = container.find('div', class_='da-wrap')\n",
        "        if not da_wrap:\n",
        "            logging.warning(f\"No da-wrap found in container {i+1}\")\n",
        "            continue\n",
        "\n",
        "        name_div = da_wrap.find('div', class_='da-title')\n",
        "        diocese_name = name_div.get_text(strip=True) if name_div else \"N/A\"\n",
        "        logging.info(f\"Diocese name: {diocese_name}\")\n",
        "\n",
        "        address_div = da_wrap.find('div', class_='da-address')\n",
        "        address_parts = []\n",
        "        if address_div:\n",
        "            for div in address_div.find_all('div', recursive=False):\n",
        "                text = div.get_text(strip=True)\n",
        "                if text:\n",
        "                    address_parts.append(text)\n",
        "\n",
        "        address = \", \".join(address_parts)\n",
        "        logging.info(f\"Address: {address}\")\n",
        "\n",
        "        website_div = da_wrap.find('div', class_='site')\n",
        "        website_url = website_div.find('a')['href'] if website_div and website_div.find('a') else \"N/A\"\n",
        "        logging.info(f\"Website: {website_url}\")\n",
        "\n",
        "        dioceses.append({\n",
        "            'Name': diocese_name,\n",
        "            'Address': address,\n",
        "            'Website': website_url\n",
        "        })\n",
        "\n",
        "    return dioceses"
      ],
      "metadata": {
        "id": "a7yOnNETIInL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Fetch and parse the HTML content from URL\n",
        "\n",
        "url = \"https://www.usccb.org/about/bishops-and-dioceses/all-dioceses\"\n",
        "soup = get_soup(url)\n",
        "\n",
        "if soup:\n",
        "    print(\"Successfully fetched and parsed the dioceses page.\")\n",
        "    # Print the first 1000 characters of the HTML to check its structure\n",
        "    print(\"First 1000 characters of the HTML:\")\n",
        "    print(soup.prettify()[:1000])\n",
        "else:\n",
        "    print(\"Failed to fetch the dioceses page. Please check your connection or the URL.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "H78OsQfwLvUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Extract dioceses information\n",
        "\n",
        "dioceses = extract_dioceses(soup)\n",
        "print(f\"Extracted information for {len(dioceses)} dioceses.\")\n",
        "\n",
        "if len(dioceses) == 0:\n",
        "    print(\"No dioceses were extracted. Printing the structure of the page:\")\n",
        "    print(soup.prettify())"
      ],
      "metadata": {
        "id": "_Ve1ydjDIKpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Create a DataFrame and display results\n",
        "\n",
        "dioceses_df = pd.DataFrame(dioceses)\n",
        "print(dioceses_df.head())"
      ],
      "metadata": {
        "id": "6peqWCFhIMZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell assumes 'dioceses_df' is available from previous cells\n",
        "# and 'supabase' client is initialized from a previous cell.\n",
        "\n",
        "print(\"Data extraction from website complete and DataFrame is ready.\")\n",
        "\n",
        "# Check if Supabase client is initialized and not using placeholder credentials\n",
        "if 'supabase' in locals() and supabase_url != \"YOUR_SUPABASE_URL\" and supabase_key != \"YOUR_SUPABASE_ANON_KEY\":\n",
        "    print(\"Attempting to insert data into Supabase table 'Dioceses'...\")\n",
        "    try:\n",
        "        for index, row in dioceses_df.iterrows():\n",
        "            # Convert row to dictionary\n",
        "            row_dict = row.to_dict()\n",
        "            # Insert data into Supabase\n",
        "            data, error = supabase.table('Dioceses').insert(row_dict).execute()\n",
        "            if error:\n",
        "                print(f\"Error inserting row {index}: {error}\")\n",
        "            # else:\n",
        "            #     print(f\"Successfully inserted row {index}\") # Optional: too verbose for many rows\n",
        "\n",
        "        print(\"Data insertion into Supabase 'Dioceses' table complete.\")\n",
        "\n",
        "        # Query and display data from the Supabase database\n",
        "        print(\"Fetching first 5 entries from the Supabase 'Dioceses' table:\")\n",
        "        # The result from execute() is typically a tuple (data, error) or a custom object.\n",
        "        # For Supabase Python client v1, it's often an APIResponse object.\n",
        "        # For Supabase Python client v2 (supabase-py), data is directly in response.data.\n",
        "        response = supabase.table('Dioceses').select('*').limit(5).execute()\n",
        "\n",
        "        if response.data:\n",
        "            results = response.data\n",
        "            if results:\n",
        "                for row_data in results:\n",
        "                    print(row_data)\n",
        "            else:\n",
        "                print(\"No data returned or empty data after successful query.\")\n",
        "        elif hasattr(response, 'error') and response.error:\n",
        "            print(f\"Error querying data: {response.error.message if hasattr(response.error, 'message') else response.error}\")\n",
        "        else:\n",
        "            # Fallback for unexpected response structure or if data is empty and no error is explicitly set\n",
        "            print(\"No data returned or an unexpected response structure. Full response:\")\n",
        "            # Be cautious printing the full response; it might be large or contain sensitive info depending on the client version and error details.\n",
        "            # print(response) \n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during Supabase operations: {e}\")\n",
        "        print(\"Please ensure the 'Dioceses' table exists in Supabase with columns: Name, Address, Website.\")\n",
        "else:\n",
        "    print(\"Supabase client not properly initialized or using placeholder credentials. Skipping Supabase operations.\")\n",
        "    print(\"Please ensure Supabase is correctly configured with actual credentials in the 'supabase-init-cell'.\")\n"
      ],
      "metadata": {
        "id": "lbPIlNkWrlr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}