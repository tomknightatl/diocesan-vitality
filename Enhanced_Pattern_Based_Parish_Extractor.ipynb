{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMv61gL6f/jBnDBtDGVWoMn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomknightatl/USCCB/blob/main/Enhanced_Pattern_Based_Parish_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjMkndZ9tA88",
        "outputId": "09e252b8-744b-4a4b-9b61-c9401c27d6b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: supabase in /usr/local/lib/python3.11/dist-packages (2.15.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (0.6.7)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.33.0)\n",
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.11/dist-packages (4.0.2)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (9.1.2)\n",
            "Requirement already satisfied: gotrue<3.0.0,>=2.11.0 in /usr/local/lib/python3.11/dist-packages (from supabase) (2.12.0)\n",
            "Requirement already satisfied: httpx<0.29,>=0.26 in /usr/local/lib/python3.11/dist-packages (from supabase) (0.28.1)\n",
            "Requirement already satisfied: postgrest<1.1,>0.19 in /usr/local/lib/python3.11/dist-packages (from supabase) (1.0.2)\n",
            "Requirement already satisfied: realtime<2.5.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from supabase) (2.4.3)\n",
            "Requirement already satisfied: storage3<0.12,>=0.10 in /usr/local/lib/python3.11/dist-packages (from supabase) (0.11.3)\n",
            "Requirement already satisfied: supafunc<0.10,>=0.9 in /usr/local/lib/python3.11/dist-packages (from supabase) (0.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json) (0.9.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.2)\n",
            "Requirement already satisfied: urllib3~=2.4.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.4.26 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.4.26)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (24.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.10 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.11.4)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.10.1)\n",
            "Requirement already satisfied: pytest-mock<4.0.0,>=3.14.0 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (3.14.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.16.0)\n",
            "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from postgrest<1.1,>0.19->supabase) (2.1.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.11.18 in /usr/local/lib/python3.11/dist-packages (from realtime<2.5.0,>=2.4.0->supabase) (3.12.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from realtime<2.5.0,>=2.4.0->supabase) (2.9.0.post0)\n",
            "Requirement already satisfied: websockets<15,>=11 in /usr/local/lib/python3.11/dist-packages (from realtime<2.5.0,>=2.4.0->supabase) (14.2)\n",
            "Requirement already satisfied: strenum<0.5.0,>=0.4.15 in /usr/local/lib/python3.11/dist-packages (from supafunc<0.10,>=0.9->supabase) (0.4.15)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json) (1.1.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.4.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.20.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10->gotrue<3.0.0,>=2.11.0->supabase) (0.4.1)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.11/dist-packages (from pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (8.3.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.1->realtime<2.5.0,>=2.4.0->supabase) (1.17.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (1.6.0)\n"
          ]
        }
      ],
      "source": [
        "# =============================================================================\n",
        "# CELL 1: Install and Import Dependencies\n",
        "# =============================================================================\n",
        "\n",
        "# Install additional dependencies for the enhanced system\n",
        "!pip install supabase dataclasses-json beautifulsoup4 selenium webdriver-manager tenacity\n",
        "\n",
        "# Your existing imports PLUS new ones for pattern detection\n",
        "import os\n",
        "import time\n",
        "import json\n",
        "import random\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass, asdict\n",
        "from enum import Enum\n",
        "from typing import List, Dict, Optional, Any\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "# Web scraping\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "\n",
        "# Your existing Supabase and AI imports\n",
        "from google.colab import userdata\n",
        "from supabase import create_client, Client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 2: Configuration (Reuse your existing setup)\n",
        "# =============================================================================\n",
        "\n",
        "# Reuse your existing configuration logic\n",
        "print(\"=== ENHANCED PARISH EXTRACTOR CONFIGURATION ===\")\n",
        "\n",
        "# GitHub and database setup (copy from your existing notebooks)\n",
        "GITHUB_REPO = 'USCCB'\n",
        "GITHUB_USERNAME = userdata.get('GitHubUserforUSCCB')\n",
        "GITHUB_PAT = userdata.get('GitHubPATforUSCCB')\n",
        "\n",
        "# Supabase configuration (copy from your existing setup)\n",
        "SUPABASE_URL = userdata.get('SUPABASE_URL')\n",
        "SUPABASE_KEY = userdata.get('SUPABASE_KEY')\n",
        "\n",
        "if SUPABASE_URL and SUPABASE_KEY:\n",
        "    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "    print(\"‚úÖ Supabase client initialized\")\n",
        "else:\n",
        "    print(\"‚ùå Supabase credentials not found\")\n",
        "    supabase = None\n",
        "\n",
        "# Processing configuration\n",
        "MAX_DIOCESES_TO_PROCESS = 5  # Start small for testing\n",
        "ENABLE_PATTERN_DETECTION = True\n",
        "SAVE_DETAILED_LOGS = True\n",
        "\n",
        "print(f\"üìä Will process {MAX_DIOCESES_TO_PROCESS} dioceses with pattern detection\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qr8OfoQNtGiM",
        "outputId": "c463f65d-8558-444e-e3ce-bc639dc0c8c1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== ENHANCED PARISH EXTRACTOR CONFIGURATION ===\n",
            "‚úÖ Supabase client initialized\n",
            "üìä Will process 5 dioceses with pattern detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Chrome Installation for Google Colab\n",
        "def ensure_chrome_installed():\n",
        "    \"\"\"Ensures Chrome is installed in the Colab environment.\"\"\"\n",
        "    try:\n",
        "        # Check if Chrome is already available\n",
        "        result = subprocess.run(['which', 'google-chrome'], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úÖ Chrome is already installed and available.\")\n",
        "            return True\n",
        "\n",
        "        print(\"üîß Chrome not found. Installing Chrome for Selenium...\")\n",
        "\n",
        "        # Install Chrome\n",
        "        os.system('apt-get update > /dev/null 2>&1')\n",
        "        os.system('wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | apt-key add - > /dev/null 2>&1')\n",
        "        os.system('echo \"deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main\" > /etc/apt/sources.list.d/google-chrome.list')\n",
        "        os.system('apt-get update > /dev/null 2>&1')\n",
        "        os.system('apt-get install -y google-chrome-stable > /dev/null 2>&1')\n",
        "\n",
        "        # Verify installation\n",
        "        result = subprocess.run(['google-chrome', '--version'], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            print(f\"‚úÖ Chrome installed successfully: {result.stdout.strip()}\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"‚ùå Chrome installation may have failed.\")\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during Chrome installation: {e}\")\n",
        "        return False\n",
        "\n",
        "# Run the installation check\n",
        "print(\"\\nüîß Checking Chrome installation...\")\n",
        "chrome_ready = ensure_chrome_installed()\n",
        "\n",
        "if chrome_ready:\n",
        "    print(\"üöÄ Ready to proceed with Selenium operations!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è You may need to restart the runtime if Chrome installation failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlIbVQ4hvkR_",
        "outputId": "2fa685d9-4f9f-4ac2-f32b-06435c2edb64"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîß Checking Chrome installation...\n",
            "‚ùå Error during Chrome installation: name 'subprocess' is not defined\n",
            "‚ö†Ô∏è You may need to restart the runtime if Chrome installation failed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 3: Enhanced Pattern Detection Classes\n",
        "# =============================================================================\n",
        "\n",
        "class DiocesePlatform(Enum):\n",
        "    SQUARESPACE = \"squarespace\"\n",
        "    WORDPRESS = \"wordpress\"\n",
        "    DRUPAL = \"drupal\"\n",
        "    CUSTOM_CMS = \"custom\"\n",
        "    STATIC_HTML = \"static\"\n",
        "    UNKNOWN = \"unknown\"\n",
        "\n",
        "class ParishListingType(Enum):\n",
        "    INTERACTIVE_MAP = \"interactive_map\"\n",
        "    STATIC_TABLE = \"static_table\"\n",
        "    CARD_GRID = \"card_grid\"\n",
        "    SIMPLE_LIST = \"simple_list\"\n",
        "    PAGINATED_LIST = \"paginated_list\"\n",
        "    SEARCHABLE_DIRECTORY = \"searchable_directory\"\n",
        "    PDF_DIRECTORY = \"pdf_directory\"\n",
        "    UNKNOWN = \"unknown\"\n",
        "\n",
        "@dataclass\n",
        "class ParishData:\n",
        "    name: str\n",
        "    address: Optional[str] = None\n",
        "    city: Optional[str] = None\n",
        "    state: Optional[str] = None\n",
        "    zip_code: Optional[str] = None\n",
        "    phone: Optional[str] = None\n",
        "    website: Optional[str] = None\n",
        "    latitude: Optional[float] = None\n",
        "    longitude: Optional[float] = None\n",
        "    pastor: Optional[str] = None\n",
        "    mass_times: Optional[str] = None\n",
        "    confidence_score: float = 0.5\n",
        "    extraction_method: str = \"unknown\"\n",
        "\n",
        "@dataclass\n",
        "class DioceseSitePattern:\n",
        "    platform: DiocesePlatform\n",
        "    listing_type: ParishListingType\n",
        "    confidence_score: float\n",
        "    extraction_method: str\n",
        "    specific_selectors: Dict[str, str]\n",
        "    javascript_required: bool\n",
        "    pagination_pattern: Optional[str] = None\n",
        "    notes: str = \"\"\n",
        "\n",
        "class PatternDetector:\n",
        "    \"\"\"Detects patterns in diocese websites for targeted extraction\"\"\"\n",
        "\n",
        "    def detect_pattern(self, html_content: str, url: str) -> DioceseSitePattern:\n",
        "        \"\"\"Analyze website content and detect the best extraction pattern\"\"\"\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "        html_lower = html_content.lower()\n",
        "\n",
        "        # Platform detection\n",
        "        platform = self._detect_platform(html_lower)\n",
        "\n",
        "        # Listing type detection\n",
        "        listing_type = self._detect_listing_type(html_lower, soup)\n",
        "\n",
        "        # JavaScript requirement\n",
        "        js_required = self._requires_javascript(html_lower)\n",
        "\n",
        "        # Determine extraction method and confidence\n",
        "        extraction_method, confidence, selectors, notes = self._determine_extraction_strategy(\n",
        "            platform, listing_type, soup, html_lower\n",
        "        )\n",
        "\n",
        "        return DioceseSitePattern(\n",
        "            platform=platform,\n",
        "            listing_type=listing_type,\n",
        "            confidence_score=confidence,\n",
        "            extraction_method=extraction_method,\n",
        "            specific_selectors=selectors,\n",
        "            javascript_required=js_required,\n",
        "            notes=notes\n",
        "        )\n",
        "\n",
        "    def _detect_platform(self, html_lower: str) -> DiocesePlatform:\n",
        "        \"\"\"Detect CMS/platform\"\"\"\n",
        "        if 'squarespace' in html_lower:\n",
        "            return DiocesePlatform.SQUARESPACE\n",
        "        elif 'wp-content' in html_lower or 'wordpress' in html_lower:\n",
        "            return DiocesePlatform.WORDPRESS\n",
        "        elif 'drupal' in html_lower:\n",
        "            return DiocesePlatform.DRUPAL\n",
        "        else:\n",
        "            return DiocesePlatform.CUSTOM_CMS\n",
        "\n",
        "    def _detect_listing_type(self, html_lower: str, soup: BeautifulSoup) -> ParishListingType:\n",
        "        \"\"\"Detect how parishes are listed\"\"\"\n",
        "        # Interactive map indicators\n",
        "        map_indicators = ['leaflet', 'google.maps', 'mapbox', 'parish-map', 'interactive']\n",
        "        if any(indicator in html_lower for indicator in map_indicators):\n",
        "            return ParishListingType.INTERACTIVE_MAP\n",
        "\n",
        "        # Table indicators\n",
        "        if soup.find('table') and ('parish' in html_lower or 'church' in html_lower):\n",
        "            return ParishListingType.STATIC_TABLE\n",
        "\n",
        "        # Card/grid layout\n",
        "        if soup.find_all(class_=re.compile(r'(card|grid|parish-item)', re.I)):\n",
        "            return ParishListingType.CARD_GRID\n",
        "\n",
        "        # Pagination\n",
        "        if any(word in html_lower for word in ['pagination', 'page-numbers', 'next-page']):\n",
        "            return ParishListingType.PAGINATED_LIST\n",
        "\n",
        "        return ParishListingType.SIMPLE_LIST\n",
        "\n",
        "    def _requires_javascript(self, html_lower: str) -> bool:\n",
        "        \"\"\"Check if JavaScript is required\"\"\"\n",
        "        js_indicators = ['react', 'angular', 'vue', 'leaflet', 'google.maps', 'ajax']\n",
        "        return any(indicator in html_lower for indicator in js_indicators)\n",
        "\n",
        "    def _determine_extraction_strategy(self, platform, listing_type, soup, html_lower):\n",
        "        \"\"\"Determine the best extraction strategy\"\"\"\n",
        "\n",
        "        if listing_type == ParishListingType.INTERACTIVE_MAP:\n",
        "            return (\n",
        "                \"interactive_map_extraction\",\n",
        "                0.9,\n",
        "                {\"map_container\": \"#map, .map-container, .parish-map\"},\n",
        "                \"Interactive map detected - will extract from JS data and markers\"\n",
        "            )\n",
        "\n",
        "        elif listing_type == ParishListingType.STATIC_TABLE:\n",
        "            return (\n",
        "                \"table_extraction\",\n",
        "                0.95,\n",
        "                {\"table\": \"table\", \"rows\": \"tr:not(:first-child)\"},\n",
        "                \"HTML table detected - most reliable extraction method\"\n",
        "            )\n",
        "\n",
        "        elif platform == DiocesePlatform.SQUARESPACE:\n",
        "            return (\n",
        "                \"squarespace_extraction\",\n",
        "                0.8,\n",
        "                {\"items\": \".summary-item, .parish-item\", \"title\": \".summary-title\"},\n",
        "                \"SquareSpace platform - using platform-specific selectors\"\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            return (\n",
        "                \"generic_extraction\",\n",
        "                0.4,\n",
        "                {\"containers\": \"[class*='parish'], [class*='church']\"},\n",
        "                \"Using generic extraction patterns\"\n",
        "            )\n",
        "\n",
        "print(\"‚úÖ Pattern detection classes loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NQqjWrmtJMr",
        "outputId": "8d57f8cc-d5d9-4022-e579-3bf98c3bdcc0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Pattern detection classes loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 4: Enhanced Extraction Classes\n",
        "# =============================================================================\n",
        "\n",
        "class BaseExtractor:\n",
        "    \"\"\"Base class for all parish extractors\"\"\"\n",
        "\n",
        "    def __init__(self, pattern: DioceseSitePattern):\n",
        "        self.pattern = pattern\n",
        "\n",
        "    def extract(self, driver, soup: BeautifulSoup, url: str) -> List[ParishData]:\n",
        "        \"\"\"Override in subclasses\"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def clean_text(self, text: str) -> str:\n",
        "        \"\"\"Clean extracted text\"\"\"\n",
        "        if not text:\n",
        "            return \"\"\n",
        "        return ' '.join(text.strip().split())\n",
        "\n",
        "    def extract_phone(self, text: str) -> Optional[str]:\n",
        "        \"\"\"Extract phone number\"\"\"\n",
        "        import re\n",
        "        phone_pattern = r'\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4}'\n",
        "        match = re.search(phone_pattern, text)\n",
        "        return match.group() if match else None\n",
        "\n",
        "class InteractiveMapExtractor(BaseExtractor):\n",
        "    \"\"\"Extract from JavaScript-powered maps\"\"\"\n",
        "\n",
        "    def extract(self, driver, soup: BeautifulSoup, url: str) -> List[ParishData]:\n",
        "        parishes = []\n",
        "\n",
        "        try:\n",
        "            # Wait for map to load\n",
        "            WebDriverWait(driver, 10).until(\n",
        "                EC.presence_of_element_located((By.CSS_SELECTOR, \"#map, .map, .parish-map\"))\n",
        "            )\n",
        "\n",
        "            # Method 1: Extract from JavaScript variables\n",
        "            parishes.extend(self._extract_from_js_variables(driver))\n",
        "\n",
        "            # Method 2: Extract from map markers (if JS method failed)\n",
        "            if not parishes:\n",
        "                parishes.extend(self._extract_from_markers(driver))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    ‚ö†Ô∏è Map extraction failed: {e}\")\n",
        "\n",
        "        return parishes\n",
        "\n",
        "    def _extract_from_js_variables(self, driver) -> List[ParishData]:\n",
        "        \"\"\"Extract from common JavaScript variable names\"\"\"\n",
        "        parishes = []\n",
        "\n",
        "        # Common variable names dioceses use\n",
        "        js_vars = [\"parishes\", \"parishData\", \"locations\", \"markers\", \"churchData\"]\n",
        "\n",
        "        for var_name in js_vars:\n",
        "            try:\n",
        "                js_data = driver.execute_script(f\"return window.{var_name};\")\n",
        "                if js_data and isinstance(js_data, list):\n",
        "                    for item in js_data:\n",
        "                        parish = self._parse_js_parish_object(item)\n",
        "                        if parish:\n",
        "                            parishes.append(parish)\n",
        "                    break\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        return parishes\n",
        "\n",
        "    def _parse_js_parish_object(self, data: Dict) -> Optional[ParishData]:\n",
        "        \"\"\"Parse parish data from JavaScript object\"\"\"\n",
        "        if not isinstance(data, dict):\n",
        "            return None\n",
        "\n",
        "        # Find name using common field names\n",
        "        name = None\n",
        "        for field in ['name', 'title', 'parishName', 'churchName']:\n",
        "            if field in data and data[field]:\n",
        "                name = str(data[field]).strip()\n",
        "                break\n",
        "\n",
        "        if not name:\n",
        "            return None\n",
        "\n",
        "        return ParishData(\n",
        "            name=name,\n",
        "            address=data.get('address', data.get('location')),\n",
        "            phone=data.get('phone', data.get('telephone')),\n",
        "            website=data.get('website', data.get('url')),\n",
        "            latitude=data.get('lat', data.get('latitude')),\n",
        "            longitude=data.get('lng', data.get('longitude')),\n",
        "            confidence_score=0.8,\n",
        "            extraction_method=\"js_variable_extraction\"\n",
        "        )\n",
        "\n",
        "    def _extract_from_markers(self, driver) -> List[ParishData]:\n",
        "        \"\"\"Extract by clicking map markers\"\"\"\n",
        "        parishes = []\n",
        "\n",
        "        try:\n",
        "            markers = driver.find_elements(By.CSS_SELECTOR, \".marker, .leaflet-marker\")\n",
        "\n",
        "            for marker in markers[:10]:  # Limit to avoid timeouts\n",
        "                try:\n",
        "                    driver.execute_script(\"arguments[0].click();\", marker)\n",
        "                    time.sleep(1)\n",
        "\n",
        "                    # Look for popup content\n",
        "                    popup = driver.find_element(By.CSS_SELECTOR, \".popup, .info-window\")\n",
        "                    text = popup.text\n",
        "\n",
        "                    if text and len(text) > 10:\n",
        "                        parishes.append(ParishData(\n",
        "                            name=text.split('\\n')[0],  # First line usually name\n",
        "                            confidence_score=0.6,\n",
        "                            extraction_method=\"marker_click_extraction\"\n",
        "                        ))\n",
        "                except:\n",
        "                    continue\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        return parishes\n",
        "\n",
        "class TableExtractor(BaseExtractor):\n",
        "    \"\"\"Extract from HTML tables\"\"\"\n",
        "\n",
        "    def extract(self, driver, soup: BeautifulSoup, url: str) -> List[ParishData]:\n",
        "        parishes = []\n",
        "\n",
        "        # Find tables that contain parish data\n",
        "        tables = soup.find_all('table')\n",
        "\n",
        "        for table in tables:\n",
        "            if self._is_parish_table(table):\n",
        "                parishes.extend(self._extract_from_table(table))\n",
        "\n",
        "        return parishes\n",
        "\n",
        "    def _is_parish_table(self, table) -> bool:\n",
        "        \"\"\"Check if table contains parish data\"\"\"\n",
        "        text = table.get_text().lower()\n",
        "        indicators = ['parish', 'church', 'address', 'phone']\n",
        "        return sum(1 for indicator in indicators if indicator in text) >= 2\n",
        "\n",
        "    def _extract_from_table(self, table) -> List[ParishData]:\n",
        "        \"\"\"Extract parishes from table\"\"\"\n",
        "        parishes = []\n",
        "        rows = table.find_all('tr')\n",
        "\n",
        "        if len(rows) < 2:\n",
        "            return parishes\n",
        "\n",
        "        # Analyze header row to map columns\n",
        "        headers = [cell.get_text().strip().lower() for cell in rows[0].find_all(['th', 'td'])]\n",
        "        column_map = self._map_table_columns(headers)\n",
        "\n",
        "        # Extract data from each row\n",
        "        for row in rows[1:]:\n",
        "            cells = row.find_all(['td', 'th'])\n",
        "            parish = self._extract_parish_from_row(cells, column_map)\n",
        "            if parish:\n",
        "                parishes.append(parish)\n",
        "\n",
        "        return parishes\n",
        "\n",
        "    def _map_table_columns(self, headers: List[str]) -> Dict[str, int]:\n",
        "        \"\"\"Map table columns to data fields\"\"\"\n",
        "        mapping = {}\n",
        "\n",
        "        for i, header in enumerate(headers):\n",
        "            if any(word in header for word in ['name', 'parish', 'church']):\n",
        "                mapping['name'] = i\n",
        "            elif 'address' in header:\n",
        "                mapping['address'] = i\n",
        "            elif 'phone' in header:\n",
        "                mapping['phone'] = i\n",
        "            elif 'website' in header or 'web' in header:\n",
        "                mapping['website'] = i\n",
        "\n",
        "        return mapping\n",
        "\n",
        "    def _extract_parish_from_row(self, cells, column_map: Dict[str, int]) -> Optional[ParishData]:\n",
        "        \"\"\"Extract parish data from table row\"\"\"\n",
        "        if not cells or 'name' not in column_map:\n",
        "            return None\n",
        "\n",
        "        name_idx = column_map['name']\n",
        "        if name_idx >= len(cells):\n",
        "            return None\n",
        "\n",
        "        name = self.clean_text(cells[name_idx].get_text())\n",
        "        if not name or len(name) < 3:\n",
        "            return None\n",
        "\n",
        "        # Extract other fields\n",
        "        address = None\n",
        "        if 'address' in column_map and column_map['address'] < len(cells):\n",
        "            address = self.clean_text(cells[column_map['address']].get_text())\n",
        "\n",
        "        phone = None\n",
        "        if 'phone' in column_map and column_map['phone'] < len(cells):\n",
        "            phone = self.extract_phone(cells[column_map['phone']].get_text())\n",
        "\n",
        "        website = None\n",
        "        if 'website' in column_map and column_map['website'] < len(cells):\n",
        "            link = cells[column_map['website']].find('a')\n",
        "            if link:\n",
        "                website = link.get('href')\n",
        "\n",
        "        return ParishData(\n",
        "            name=name,\n",
        "            address=address,\n",
        "            phone=phone,\n",
        "            website=website,\n",
        "            confidence_score=0.9,  # Tables are very reliable\n",
        "            extraction_method=\"table_extraction\"\n",
        "        )\n",
        "\n",
        "class GenericExtractor(BaseExtractor):\n",
        "    \"\"\"Fallback extractor for unrecognized patterns\"\"\"\n",
        "\n",
        "    def extract(self, driver, soup: BeautifulSoup, url: str) -> List[ParishData]:\n",
        "        parishes = []\n",
        "\n",
        "        # Look for elements that might contain parish info\n",
        "        selectors = [\n",
        "            \"[class*='parish']\",\n",
        "            \"[class*='church']\",\n",
        "            \"[class*='location']\",\n",
        "            \"h2, h3, h4\"  # Headers that might be parish names\n",
        "        ]\n",
        "\n",
        "        for selector in selectors:\n",
        "            elements = soup.select(selector)\n",
        "            for element in elements[:20]:  # Limit to avoid noise\n",
        "                text = element.get_text().strip()\n",
        "                if self._looks_like_parish_name(text):\n",
        "                    parishes.append(ParishData(\n",
        "                        name=text,\n",
        "                        confidence_score=0.3,\n",
        "                        extraction_method=\"generic_extraction\"\n",
        "                    ))\n",
        "\n",
        "        return parishes\n",
        "\n",
        "    def _looks_like_parish_name(self, text: str) -> bool:\n",
        "        \"\"\"Check if text looks like a parish name\"\"\"\n",
        "        if not text or len(text) < 5 or len(text) > 100:\n",
        "            return False\n",
        "\n",
        "        parish_indicators = ['parish', 'church', 'st.', 'saint', 'our lady', 'holy']\n",
        "        return any(indicator in text.lower() for indicator in parish_indicators)\n",
        "\n",
        "print(\"‚úÖ Extraction classes loaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGq9bLEhtQWc",
        "outputId": "bae0ad2d-b213-4897-c625-50ba700ca180"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extraction classes loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 5: Integration with Your Existing Database Functions\n",
        "# =============================================================================\n",
        "\n",
        "def prepare_parish_for_supabase(parish_data: ParishData, diocese_name: str, diocese_url: str) -> Dict:\n",
        "    \"\"\"Convert ParishData to format compatible with your existing Supabase schema\"\"\"\n",
        "\n",
        "    return {\n",
        "        'Name': parish_data.name,\n",
        "        'Status': 'Parish',  # Default status\n",
        "        'Deanery': None,  # Will be populated later if available\n",
        "        'Street Address': parish_data.address,\n",
        "        'City': parish_data.city,\n",
        "        'State': parish_data.state,\n",
        "        'Zip Code': parish_data.zip_code,\n",
        "        'Phone Number': parish_data.phone,\n",
        "        'Web': parish_data.website,\n",
        "        # Additional metadata\n",
        "        'diocese_name': diocese_name,\n",
        "        'diocese_url': diocese_url,\n",
        "        'extraction_method': parish_data.extraction_method,\n",
        "        'confidence_score': parish_data.confidence_score,\n",
        "        'extracted_at': datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "def enhanced_safe_upsert_to_supabase(parishes: List[ParishData], diocese_name: str, diocese_url: str):\n",
        "    \"\"\"Enhanced version of your existing Supabase upsert function\"\"\"\n",
        "\n",
        "    if not supabase:\n",
        "        print(\"  ‚ùå Supabase not available\")\n",
        "        return False\n",
        "\n",
        "    success_count = 0\n",
        "\n",
        "    for parish in parishes:\n",
        "        try:\n",
        "            # Convert to your existing schema format\n",
        "            supabase_data = prepare_parish_for_supabase(parish, diocese_name, diocese_url)\n",
        "\n",
        "            # Remove None values\n",
        "            clean_data = {k: v for k, v in supabase_data.items() if v is not None}\n",
        "\n",
        "            # Use your existing upsert logic\n",
        "            response = supabase.table('Parishes').insert(clean_data).execute()\n",
        "\n",
        "            if hasattr(response, 'error') and response.error:\n",
        "                print(f\"    ‚ùå Database error for {parish.name}: {response.error}\")\n",
        "            else:\n",
        "                success_count += 1\n",
        "                print(f\"    ‚úÖ Saved: {parish.name} (confidence: {parish.confidence_score:.2f})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"    ‚ùå Error saving {parish.name}: {e}\")\n",
        "\n",
        "    print(f\"  üìä Successfully saved {success_count}/{len(parishes)} parishes\")\n",
        "    return success_count > 0\n",
        "\n",
        "print(\"‚úÖ Database integration functions loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcL9MpN5tSQR",
        "outputId": "ca1a13c3-524e-41ec-bdbc-dc4664ab6e77"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Database integration functions loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 6: Master Processing Function\n",
        "# =============================================================================\n",
        "\n",
        "def process_diocese_with_pattern_detection(diocese_info: Dict, driver) -> Dict:\n",
        "    \"\"\"\n",
        "    Enhanced version of your existing diocese processing function\n",
        "    \"\"\"\n",
        "\n",
        "    diocese_url = diocese_info['url']\n",
        "    diocese_name = diocese_info['name']\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üîç ENHANCED PROCESSING: {diocese_name}\")\n",
        "    print(f\"üìç URL: {diocese_url}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    result = {\n",
        "        'diocese_name': diocese_name,\n",
        "        'diocese_url': diocese_url,\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'pattern_detected': None,\n",
        "        'parishes_found': [],\n",
        "        'success': False,\n",
        "        'extraction_methods_used': [],\n",
        "        'processing_time': 0,\n",
        "        'errors': []\n",
        "    }\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Step 1: Load the page\n",
        "        print(\"  üì• Loading diocese website...\")\n",
        "        driver.get(diocese_url)\n",
        "        time.sleep(3)\n",
        "\n",
        "        html_content = driver.page_source\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "        # Step 2: Detect pattern\n",
        "        print(\"  üîç Detecting website pattern...\")\n",
        "        detector = PatternDetector()\n",
        "        pattern = detector.detect_pattern(html_content, diocese_url)\n",
        "\n",
        "        result['pattern_detected'] = {\n",
        "            'platform': pattern.platform.value,\n",
        "            'listing_type': pattern.listing_type.value,\n",
        "            'confidence': pattern.confidence_score,\n",
        "            'extraction_method': pattern.extraction_method,\n",
        "            'javascript_required': pattern.javascript_required,\n",
        "            'notes': pattern.notes\n",
        "        }\n",
        "\n",
        "        print(f\"    üìã Platform: {pattern.platform.value}\")\n",
        "        print(f\"    üìä Listing Type: {pattern.listing_type.value}\")\n",
        "        print(f\"    üéØ Confidence: {pattern.confidence_score:.2f}\")\n",
        "        print(f\"    ‚öôÔ∏è Method: {pattern.extraction_method}\")\n",
        "\n",
        "        # Step 3: Extract parishes using pattern-specific method\n",
        "        parishes = []\n",
        "\n",
        "        # Try primary extraction method\n",
        "        if pattern.listing_type == ParishListingType.INTERACTIVE_MAP:\n",
        "            extractor = InteractiveMapExtractor(pattern)\n",
        "        elif pattern.listing_type == ParishListingType.STATIC_TABLE:\n",
        "            extractor = TableExtractor(pattern)\n",
        "        else:\n",
        "            extractor = GenericExtractor(pattern)\n",
        "\n",
        "        print(f\"  üîÑ Extracting using {extractor.__class__.__name__}...\")\n",
        "        parishes = extractor.extract(driver, soup, diocese_url)\n",
        "        result['extraction_methods_used'].append(extractor.__class__.__name__)\n",
        "\n",
        "        # Step 4: Fallback methods if primary failed\n",
        "        if not parishes:\n",
        "            print(\"  üîÑ Primary method found no parishes, trying fallbacks...\")\n",
        "\n",
        "            # Try other extractors\n",
        "            fallback_extractors = [\n",
        "                TableExtractor(pattern),\n",
        "                InteractiveMapExtractor(pattern),\n",
        "                GenericExtractor(pattern)\n",
        "            ]\n",
        "\n",
        "            for fallback_extractor in fallback_extractors:\n",
        "                if fallback_extractor.__class__.__name__ in result['extraction_methods_used']:\n",
        "                    continue  # Skip if already tried\n",
        "\n",
        "                try:\n",
        "                    print(f\"    üîÑ Trying {fallback_extractor.__class__.__name__}...\")\n",
        "                    fallback_parishes = fallback_extractor.extract(driver, soup, diocese_url)\n",
        "                    if fallback_parishes:\n",
        "                        parishes.extend(fallback_parishes)\n",
        "                        result['extraction_methods_used'].append(fallback_extractor.__class__.__name__)\n",
        "                        break\n",
        "                except Exception as e:\n",
        "                    print(f\"    ‚ùå {fallback_extractor.__class__.__name__} failed: {e}\")\n",
        "\n",
        "        # Step 5: Process results\n",
        "        if parishes:\n",
        "            # Remove duplicates and validate\n",
        "            unique_parishes = []\n",
        "            seen_names = set()\n",
        "\n",
        "            for parish in parishes:\n",
        "                name_key = parish.name.lower().strip()\n",
        "                if name_key not in seen_names and len(parish.name) > 2:\n",
        "                    unique_parishes.append(parish)\n",
        "                    seen_names.add(name_key)\n",
        "\n",
        "            result['parishes_found'] = unique_parishes\n",
        "            result['success'] = True\n",
        "\n",
        "            print(f\"  ‚úÖ Found {len(unique_parishes)} unique parishes\")\n",
        "\n",
        "            # Step 6: Save to database\n",
        "            if unique_parishes:\n",
        "                print(\"  üíæ Saving to database...\")\n",
        "                enhanced_safe_upsert_to_supabase(unique_parishes, diocese_name, diocese_url)\n",
        "\n",
        "        else:\n",
        "            print(\"  ‚ùå No parishes found with any extraction method\")\n",
        "            result['success'] = False\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = str(e)\n",
        "        result['errors'].append(error_msg)\n",
        "        print(f\"  ‚ùå Processing error: {error_msg}\")\n",
        "\n",
        "    finally:\n",
        "        result['processing_time'] = time.time() - start_time\n",
        "        print(f\"  ‚è±Ô∏è Completed in {result['processing_time']:.1f}s\")\n",
        "\n",
        "    return result\n",
        "\n",
        "print(\"‚úÖ Master processing function loaded\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ9oxFJqtW97",
        "outputId": "57c33fb5-6847-4958-c606-b940fb8eadfe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Master processing function loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 7: Main Execution (Modified from your existing logic)\n",
        "# =============================================================================\n",
        "\n",
        "# Setup driver (reuse your existing WebDriver setup)\n",
        "def setup_enhanced_driver():\n",
        "    \"\"\"Enhanced driver setup with pattern detection optimizations\"\"\"\n",
        "    options = Options()\n",
        "    options.add_argument(\"--headless\")\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    options.add_argument(\"--disable-gpu\")\n",
        "    options.add_argument(\"--window-size=1920,1080\")\n",
        "\n",
        "    # Additional options for better JavaScript support\n",
        "    options.add_argument(\"--enable-javascript\")\n",
        "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
        "\n",
        "    driver = webdriver.Chrome(\n",
        "        service=Service(ChromeDriverManager().install()),\n",
        "        options=options\n",
        "    )\n",
        "    return driver\n",
        "\n",
        "# Get dioceses to process (reuse your existing Supabase query logic)\n",
        "if supabase:\n",
        "    try:\n",
        "        print(\"üì• Fetching dioceses from database...\")\n",
        "\n",
        "        # Get dioceses that don't have parishes yet (modify this query as needed)\n",
        "        response = supabase.table('Dioceses').select('Website, Name').execute()\n",
        "        all_dioceses = response.data if response.data else []\n",
        "\n",
        "        # Randomly sample for testing\n",
        "        if len(all_dioceses) > MAX_DIOCESES_TO_PROCESS:\n",
        "            dioceses_to_process = random.sample(all_dioceses, MAX_DIOCESES_TO_PROCESS)\n",
        "        else:\n",
        "            dioceses_to_process = all_dioceses\n",
        "\n",
        "        print(f\"üìä Selected {len(dioceses_to_process)} dioceses for enhanced processing\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error fetching dioceses: {e}\")\n",
        "        dioceses_to_process = []\n",
        "else:\n",
        "    print(\"‚ùå No Supabase connection, using test data\")\n",
        "    dioceses_to_process = [\n",
        "        {'Name': 'Diocese of Test', 'Website': 'https://example.com'}\n",
        "    ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPgmR8FFtXax",
        "outputId": "29735671-6c8f-4653-ca13-f22ef0d922b1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Fetching dioceses from database...\n",
            "üìä Selected 5 dioceses for enhanced processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# CELL 8: Execute Enhanced Processing\n",
        "# =============================================================================\n",
        "\n",
        "if dioceses_to_process:\n",
        "    print(f\"\\nüöÄ Starting enhanced pattern-based processing...\")\n",
        "\n",
        "    # Initialize driver\n",
        "    driver = setup_enhanced_driver()\n",
        "\n",
        "    # Track results\n",
        "    all_results = []\n",
        "    summary_stats = {\n",
        "        'total_dioceses': len(dioceses_to_process),\n",
        "        'successful_extractions': 0,\n",
        "        'total_parishes_found': 0,\n",
        "        'pattern_distribution': {},\n",
        "        'extraction_method_usage': {},\n",
        "        'average_confidence': 0.0\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        for i, diocese_info in enumerate(dioceses_to_process, 1):\n",
        "            print(f\"\\nüìç Diocese {i}/{len(dioceses_to_process)}\")\n",
        "\n",
        "            # Convert from your existing format to expected format\n",
        "            diocese_data = {\n",
        "                'name': diocese_info.get('Name', 'Unknown'),\n",
        "                'url': diocese_info.get('Website', '')\n",
        "            }\n",
        "\n",
        "            if not diocese_data['url']:\n",
        "                print(f\"  ‚ö†Ô∏è Skipping {diocese_data['name']} - no URL\")\n",
        "                continue\n",
        "\n",
        "            # Process with enhanced system\n",
        "            result = process_diocese_with_pattern_detection(diocese_data, driver)\n",
        "            all_results.append(result)\n",
        "\n",
        "            # Update summary statistics\n",
        "            if result['success']:\n",
        "                summary_stats['successful_extractions'] += 1\n",
        "                summary_stats['total_parishes_found'] += len(result['parishes_found'])\n",
        "\n",
        "                # Track pattern distribution\n",
        "                if result['pattern_detected']:\n",
        "                    pattern_key = f\"{result['pattern_detected']['platform']}_{result['pattern_detected']['listing_type']}\"\n",
        "                    summary_stats['pattern_distribution'][pattern_key] = summary_stats['pattern_distribution'].get(pattern_key, 0) + 1\n",
        "\n",
        "                # Track extraction methods\n",
        "                for method in result['extraction_methods_used']:\n",
        "                    summary_stats['extraction_method_usage'][method] = summary_stats['extraction_method_usage'].get(method, 0) + 1\n",
        "\n",
        "            # Be respectful - pause between requests\n",
        "            if i < len(dioceses_to_process):\n",
        "                time.sleep(2)\n",
        "\n",
        "    finally:\n",
        "        # Clean up\n",
        "        driver.quit()\n",
        "        print(\"\\nüßπ WebDriver closed\")\n",
        "\n",
        "    # Calculate final statistics\n",
        "    if summary_stats['successful_extractions'] > 0:\n",
        "        summary_stats['success_rate'] = (summary_stats['successful_extractions'] / summary_stats['total_dioceses']) * 100\n",
        "        summary_stats['avg_parishes_per_diocese'] = summary_stats['total_parishes_found'] / summary_stats['successful_extractions']\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "T0E2QoFmtaR6",
        "outputId": "b67de165-d665-461e-eb6e-66f9bc1793f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ Starting enhanced pattern-based processing...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WebDriverException",
          "evalue": "Message: unknown error: cannot find Chrome binary\nStacktrace:\n#0 0x5b2e128174e3 <unknown>\n#1 0x5b2e12546c76 <unknown>\n#2 0x5b2e1256d757 <unknown>\n#3 0x5b2e1256c029 <unknown>\n#4 0x5b2e125aaccc <unknown>\n#5 0x5b2e125aa47f <unknown>\n#6 0x5b2e125a1de3 <unknown>\n#7 0x5b2e125772dd <unknown>\n#8 0x5b2e1257834e <unknown>\n#9 0x5b2e127d73e4 <unknown>\n#10 0x5b2e127db3d7 <unknown>\n#11 0x5b2e127e5b20 <unknown>\n#12 0x5b2e127dc023 <unknown>\n#13 0x5b2e127aa1aa <unknown>\n#14 0x5b2e128006b8 <unknown>\n#15 0x5b2e12800847 <unknown>\n#16 0x5b2e12810243 <unknown>\n#17 0x78f7904d6ac3 <unknown>\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9d3745024605>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Initialize driver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_enhanced_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Track results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-db7f4941d26e>\u001b[0m in \u001b[0;36msetup_enhanced_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--disable-blink-features=AutomationControlled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     driver = webdriver.Chrome(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mservice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChromeDriverManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mbrowser_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDesiredCapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHROME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mvendor_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"goog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options, locator_converter, web_element_cls, client_config)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authenticator_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fedcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFedCM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sessionId\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"capabilities\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: cannot find Chrome binary\nStacktrace:\n#0 0x5b2e128174e3 <unknown>\n#1 0x5b2e12546c76 <unknown>\n#2 0x5b2e1256d757 <unknown>\n#3 0x5b2e1256c029 <unknown>\n#4 0x5b2e125aaccc <unknown>\n#5 0x5b2e125aa47f <unknown>\n#6 0x5b2e125a1de3 <unknown>\n#7 0x5b2e125772dd <unknown>\n#8 0x5b2e1257834e <unknown>\n#9 0x5b2e127d73e4 <unknown>\n#10 0x5b2e127db3d7 <unknown>\n#11 0x5b2e127e5b20 <unknown>\n#12 0x5b2e127dc023 <unknown>\n#13 0x5b2e127aa1aa <unknown>\n#14 0x5b2e128006b8 <unknown>\n#15 0x5b2e12800847 <unknown>\n#16 0x5b2e12810243 <unknown>\n#17 0x78f7904d6ac3 <unknown>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "    # CELL 9: Display Results and Analysis\n",
        "    # =============================================================================\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"üìä ENHANCED EXTRACTION SUMMARY\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total dioceses processed: {summary_stats['total_dioceses']}\")\n",
        "    print(f\"Successful extractions: {summary_stats['successful_extractions']}\")\n",
        "    print(f\"Success rate: {summary_stats.get('success_rate', 0):.1f}%\")\n",
        "    print(f\"Total parishes found: {summary_stats['total_parishes_found']}\")\n",
        "\n",
        "    if summary_stats['successful_extractions'] > 0:\n",
        "        print(f\"Average parishes per diocese: {summary_stats.get('avg_parishes_per_diocese', 0):.1f}\")\n",
        "\n",
        "    print(f\"\\nüìà Pattern Distribution:\")\n",
        "    for pattern, count in summary_stats['pattern_distribution'].items():\n",
        "        percentage = (count / summary_stats['total_dioceses']) * 100\n",
        "        print(f\"  {pattern.replace('_', ' ').title()}: {count} dioceses ({percentage:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nüîß Extraction Method Usage:\")\n",
        "    for method, count in summary_stats['extraction_method_usage'].items():\n",
        "        print(f\"  {method}: {count} times\")\n",
        "\n",
        "    print(f\"\\nüîç Detailed Results:\")\n",
        "    for result in all_results:\n",
        "        status = \"‚úÖ\" if result['success'] else \"‚ùå\"\n",
        "        parish_count = len(result['parishes_found'])\n",
        "        pattern_info = \"\"\n",
        "        if result['pattern_detected']:\n",
        "            pattern_info = f\" [{result['pattern_detected']['platform']} / {result['pattern_detected']['listing_type']}]\"\n",
        "\n",
        "        print(f\"  {status} {result['diocese_name']}: {parish_count} parishes{pattern_info}\")\n",
        "\n",
        "        # Show extraction methods used\n",
        "        if result['extraction_methods_used']:\n",
        "            methods = ', '.join(result['extraction_methods_used'])\n",
        "            print(f\"      Methods: {methods}\")\n",
        "\n",
        "        # Show any errors\n",
        "        if result['errors']:\n",
        "            for error in result['errors']:\n",
        "                print(f\"      Error: {error[:100]}...\")\n",
        "\n",
        "    # Save summary to file for analysis\n",
        "    summary_filename = f\"extraction_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    with open(summary_filename, 'w') as f:\n",
        "        json.dump({\n",
        "            'summary_stats': summary_stats,\n",
        "            'detailed_results': all_results\n",
        "        }, f, indent=2, default=str)\n",
        "\n",
        "    print(f\"\\nüíæ Detailed results saved to: {summary_filename}\")\n",
        "\n",
        "else:\n",
        "    print(\"‚ùå No dioceses to process\")\n",
        "\n",
        "print(f\"\\nüéâ Enhanced pattern-based extraction complete!\")\n",
        "print(f\"{'='*70}\")"
      ],
      "metadata": {
        "id": "ZT9jvX1etexA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}