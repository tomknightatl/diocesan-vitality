{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomknightatl/USCCB/blob/main/Build_Parishes_Database_Using_AgenticAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1:\n",
        "# Import required code\n",
        "!wget https://raw.githubusercontent.com/tomknightatl/USCCB/main/llm_utils.py"
      ],
      "metadata": {
        "id": "5kZpoTCpVIut",
        "outputId": "7100fc3d-c9f8-4a99-928d-2cd6f764e4ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-27 20:02:10--  https://raw.githubusercontent.com/tomknightatl/USCCB/main/llm_utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1638 (1.6K) [text/plain]\n",
            "Saving to: ‘llm_utils.py’\n",
            "\n",
            "llm_utils.py        100%[===================>]   1.60K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-05-27 20:02:11 (28.6 MB/s) - ‘llm_utils.py’ saved [1638/1638]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qIm-qDFgrqK3",
        "outputId": "44f5378c-bb9a-45a7-c81a-9428c3b933fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supabase\n",
            "  Downloading supabase-2.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.11/dist-packages (9.1.2)\n",
            "Collecting gotrue<3.0.0,>=2.11.0 (from supabase)\n",
            "  Downloading gotrue-2.12.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx<0.29,>=0.26 in /usr/local/lib/python3.11/dist-packages (from supabase) (0.28.1)\n",
            "Collecting postgrest<1.1,>0.19 (from supabase)\n",
            "  Downloading postgrest-1.0.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting realtime<2.5.0,>=2.4.0 (from supabase)\n",
            "  Downloading realtime-2.4.3-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting storage3<0.12,>=0.10 (from supabase)\n",
            "  Downloading storage3-0.11.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting supafunc<0.10,>=0.9 (from supabase)\n",
            "  Downloading supafunc-0.9.4-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from gotrue<3.0.0,>=2.11.0->supabase) (2.10.1)\n",
            "Collecting pytest-mock<4.0.0,>=3.14.0 (from gotrue<3.0.0,>=2.11.0->supabase)\n",
            "  Downloading pytest_mock-3.14.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.16.0)\n",
            "Collecting deprecation<3.0.0,>=2.1.0 (from postgrest<1.1,>0.19->supabase)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Collecting aiohttp<4.0.0,>=3.11.18 (from realtime<2.5.0,>=2.4.0->supabase)\n",
            "  Downloading aiohttp-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from realtime<2.5.0,>=2.4.0->supabase) (2.9.0.post0)\n",
            "Collecting websockets<15,>=11 (from realtime<2.5.0,>=2.4.0->supabase)\n",
            "  Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting strenum<0.5.0,>=0.4.15 (from supafunc<0.10,>=0.9->supabase)\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.11.18->realtime<2.5.0,>=2.4.0->supabase) (1.20.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation<3.0.0,>=2.1.0->postgrest<1.1,>0.19->supabase) (24.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: pytest>=6.2.5 in /usr/local/lib/python3.11/dist-packages (from pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (8.3.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.1->realtime<2.5.0,>=2.4.0->supabase) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue<3.0.0,>=2.11.0->supabase) (4.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest>=6.2.5->pytest-mock<4.0.0,>=3.14.0->gotrue<3.0.0,>=2.11.0->supabase) (1.6.0)\n",
            "Downloading supabase-2.15.2-py3-none-any.whl (17 kB)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gotrue-2.12.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading postgrest-1.0.2-py3-none-any.whl (22 kB)\n",
            "Downloading realtime-2.4.3-py3-none-any.whl (22 kB)\n",
            "Downloading storage3-0.11.3-py3-none-any.whl (17 kB)\n",
            "Downloading supafunc-0.9.4-py3-none-any.whl (7.8 kB)\n",
            "Downloading aiohttp-3.12.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading pytest_mock-3.14.1-py3-none-any.whl (9.9 kB)\n",
            "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: strenum, websockets, psycopg2-binary, deprecation, pytest-mock, aiohttp, realtime, supafunc, storage3, postgrest, gotrue, supabase\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 15.0.1\n",
            "    Uninstalling websockets-15.0.1:\n",
            "      Successfully uninstalled websockets-15.0.1\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.11.15\n",
            "    Uninstalling aiohttp-3.11.15:\n",
            "      Successfully uninstalled aiohttp-3.11.15\n",
            "Successfully installed aiohttp-3.12.2 deprecation-2.1.0 gotrue-2.12.0 postgrest-1.0.2 psycopg2-binary-2.9.10 pytest-mock-3.14.1 realtime-2.4.3 storage3-0.11.3 strenum-0.4.15 supabase-2.15.2 supafunc-0.9.4 websockets-14.2\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Import required libraries\n",
        "!pip install supabase google-generativeai psycopg2-binary tenacity\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "from urllib.parse import urlparse\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: User-configurable parameters, Supabase Setup, and Data Retrieval\n",
        "\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "from supabase import create_client, Client\n",
        "import os # For environment variables if needed, and MAX_URLS_TO_PROCESS logic\n",
        "import random\n",
        "\n",
        "print(\"--- User Configurable Parameters & Supabase Setup ---\")\n",
        "\n",
        "# --- Processing Limit Configuration ---\n",
        "# Set the maximum number of parish directory URLs to process (None = process all)\n",
        "MAX_URLS_TO_PROCESS = 5  # Change this number or set to None to process all\n",
        "                         # STARTING WITH A SMALL NUMBER FOR TESTING\n",
        "\n",
        "if MAX_URLS_TO_PROCESS:\n",
        "    print(f\"Processing will be limited to {MAX_URLS_TO_PROCESS} randomly selected URLs.\")\n",
        "else:\n",
        "    print(\"Processing will include all relevant URLs from DiocesesParishDirectory.\")\n",
        "\n",
        "# --- Supabase Configuration ---\n",
        "SUPABASE_URL = None\n",
        "SUPABASE_KEY = None\n",
        "SUPABASE_URL_FROM_USERDATA = userdata.get('SUPABASE_URL')\n",
        "SUPABASE_KEY_FROM_USERDATA = userdata.get('SUPABASE_KEY')\n",
        "\n",
        "if SUPABASE_URL_FROM_USERDATA:\n",
        "    SUPABASE_URL = SUPABASE_URL_FROM_USERDATA\n",
        "if SUPABASE_KEY_FROM_USERDATA:\n",
        "    SUPABASE_KEY = SUPABASE_KEY_FROM_USERDATA\n",
        "\n",
        "supabase: Client = None\n",
        "if SUPABASE_URL and SUPABASE_KEY:\n",
        "    try:\n",
        "        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
        "        print(\"Supabase client initialized successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Supabase client: {e}\")\n",
        "        supabase = None\n",
        "else:\n",
        "    print(\"Supabase URL and/or Key NOT loaded. Please check Colab Secrets.\")\n",
        "    print(\"Required secrets: SUPABASE_URL, SUPABASE_KEY\")\n",
        "\n",
        "# --- GenAI API Key Setup ---\n",
        "GENAI_API_KEY_FROM_USERDATA = userdata.get('GENAI_API_KEY_USCCB') # Assuming same secret name as other notebook\n",
        "GENAI_API_KEY = None\n",
        "\n",
        "if GENAI_API_KEY_FROM_USERDATA and GENAI_API_KEY_FROM_USERDATA not in [\"YOUR_API_KEY_PLACEHOLDER\", \"SET_YOUR_KEY_HERE\"]:\n",
        "    GENAI_API_KEY = GENAI_API_KEY_FROM_USERDATA\n",
        "\n",
        "if GENAI_API_KEY:\n",
        "    try:\n",
        "        genai.configure(api_key=GENAI_API_KEY)\n",
        "        print(\"GenAI configured successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error configuring GenAI with key: {e}. GenAI features might not work.\")\n",
        "        GENAI_API_KEY = None # Ensure it's None if configuration fails\n",
        "else:\n",
        "    print(\"GenAI API Key is not set (Secret: GENAI_API_KEY_USCCB). LLM features will not work.\")\n",
        "\n",
        "# --- Data Retrieval from Supabase ---\n",
        "urls_to_process = []\n",
        "if supabase:\n",
        "    try:\n",
        "        print(\"Fetching parish directory URLs from DiocesesParishDirectory table...\")\n",
        "        # Fetch non-null, non-empty parish_directory_url\n",
        "        query = supabase.table('DiocesesParishDirectory').select('parish_directory_url').not_.is_('parish_directory_url', 'null').not_.eq('parish_directory_url', '')\n",
        "\n",
        "        response = query.execute()\n",
        "\n",
        "        if response.data:\n",
        "            fetched_urls = [item['parish_directory_url'] for item in response.data if item['parish_directory_url']]\n",
        "            print(f\"Successfully fetched {len(fetched_urls)} URLs from Supabase.\")\n",
        "\n",
        "            if MAX_URLS_TO_PROCESS and len(fetched_urls) > MAX_URLS_TO_PROCESS:\n",
        "                urls_to_process = random.sample(fetched_urls, MAX_URLS_TO_PROCESS)\n",
        "                print(f\"Randomly selected {len(urls_to_process)} URLs for processing.\")\n",
        "            else:\n",
        "                urls_to_process = fetched_urls\n",
        "                print(f\"Processing all {len(urls_to_process)} fetched URLs.\")\n",
        "        else:\n",
        "            print(\"No parish directory URLs found in DiocesesParishDirectory or error in fetching.\")\n",
        "            if hasattr(response, 'error') and response.error:\n",
        "                 print(f\"Supabase error: {response.error}\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching URLs from Supabase: {e}\")\n",
        "        urls_to_process = []\n",
        "else:\n",
        "    print(\"Supabase client not initialized. Cannot fetch URLs.\")\n",
        "\n",
        "if not urls_to_process:\n",
        "    print(\"No URLs to process. Further steps might be skipped or fail.\")\n",
        "else:\n",
        "    print(f\"Prepared {len(urls_to_process)} URLs for processing.\")\n",
        "\n",
        "# For subsequent cells to use, we will name the list of URLs `urls` as in the original notebook\n",
        "urls = [(url,) for url in urls_to_process] # Keep the tuple structure if downstream code expects it\n",
        "\n",
        "print(\"--- End User Configurable Parameters & Supabase Setup ---\")"
      ],
      "metadata": {
        "id": "KIVTfVlOrtIe",
        "outputId": "e38ae5ef-58c5-4a92-bf7c-4c8b685e31a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- User Configurable Parameters & Supabase Setup ---\n",
            "Processing will be limited to 5 randomly selected URLs.\n",
            "Supabase client initialized successfully.\n",
            "GenAI configured successfully.\n",
            "Fetching parish directory URLs from DiocesesParishDirectory table...\n",
            "Successfully fetched 192 URLs from Supabase.\n",
            "Randomly selected 5 URLs for processing.\n",
            "Prepared 5 URLs for processing.\n",
            "--- End User Configurable Parameters & Supabase Setup ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Process each URL using Gemini API\n",
        "from llm_utils import invoke_gemini_model\n",
        "import json\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "def extract_domain(url):\n",
        "    parsed_url = urlparse(url)\n",
        "    return parsed_url.netloc\n",
        "\n",
        "def process_url_with_gemini(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extract visible text from the webpage\n",
        "    visible_text = ' '.join([s for s in soup.stripped_strings])\n",
        "\n",
        "    # Prepare the prompt for Gemini\n",
        "    prompt = f\"\"\"\n",
        "    Analyze the following webpage content, which is from the URL {url}.\n",
        "    Extract parish information. The information should include:\n",
        "    Name, Status, Deanery, EST (Established Date), Street Address, City, State, Zipcode, Phone Number, and Website.\n",
        "    If any specific piece of information is not found or not applicable, use the JSON value null for that field.\n",
        "    Format the output as a single, valid JSON object with these exact keys:\n",
        "    \"Name\", \"Status\", \"Deanery\", \"EST\", \"Street Address\", \"City\", \"State\", \"Zipcode\", \"Phone Number\", \"Website\".\n",
        "\n",
        "    Webpage content (first 40000 characters):\n",
        "    {visible_text[:40000]}\n",
        "    \"\"\"\n",
        "\n",
        "    # Call Gemini API\n",
        "    try:\n",
        "        # Ensure GENAI_API_KEY is loaded and genai is configured (done in Cell 3)\n",
        "        if 'GENAI_API_KEY' not in globals() or not GENAI_API_KEY:\n",
        "            print(\"GenAI API Key not configured. Skipping LLM call.\")\n",
        "            return None\n",
        "\n",
        "        # Call the shared Gemini function\n",
        "        response_text = invoke_gemini_model(prompt_text=prompt) # invoke_gemini_model is from llm_utils\n",
        "\n",
        "        print(f\"Gemini API Response: {response_text}\") # Log the raw API response\n",
        "\n",
        "        # Attempt to parse the JSON response\n",
        "        # Gemini might sometimes wrap JSON in ```json ... ```, so try to strip that\n",
        "        if response_text.strip().startswith(\"```json\"):\n",
        "            content_to_parse = response_text.strip()[7:-3].strip()\n",
        "        elif response_text.strip().startswith(\"```\"): # Generic backticks\n",
        "            content_to_parse = response_text.strip()[3:-3].strip()\n",
        "        else:\n",
        "            content_to_parse = response_text.strip()\n",
        "\n",
        "        extracted_data = json.loads(content_to_parse)\n",
        "        return extracted_data\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"JSON Decode Error: {str(e)}\")\n",
        "        print(f\"Raw API Response that failed parsing: {response_text}\")\n",
        "        # Return a dict with nulls to indicate parsing failure but allow DB storage of this failure\n",
        "        return {\"Name\": None, \"Status\": \"JSON Decode Error\", \"Deanery\": None, \"EST\": None,\n",
        "                \"Street Address\": str(e), \"City\": None, \"State\": None, \"Zipcode\": None,\n",
        "                \"Phone Number\": None, \"Website\": None, \"source_url\": url, \"domain\": extract_domain(url)}\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling Gemini API: {str(e)}\")\n",
        "        # Return a dict with nulls to indicate API error\n",
        "        return {\"Name\": None, \"Status\": \"API Error\", \"Deanery\": None, \"EST\": None,\n",
        "                \"Street Address\": str(e), \"City\": None, \"State\": None, \"Zipcode\": None,\n",
        "                \"Phone Number\": None, \"Website\": None, \"source_url\": url, \"domain\": extract_domain(url)}\n",
        "\n",
        "# Process each URL\n",
        "for url_tuple in urls: # Assuming urls is a list of tuples from Cell 3\n",
        "    url = url_tuple[0]\n",
        "    print(f\"Processing URL: {url}\")\n",
        "\n",
        "    try:\n",
        "        parish_data = process_url_with_gemini(url)\n",
        "\n",
        "        if parish_data and supabase: # Ensure data and supabase client exist\n",
        "            # Add source_url and domain if not already added by error handling in process_url_with_gemini\n",
        "            if 'source_url' not in parish_data:\n",
        "                 parish_data['source_url'] = url\n",
        "            if 'domain' not in parish_data:\n",
        "                 parish_data['domain'] = extract_domain(url)\n",
        "\n",
        "            # Prepare data for Supabase, ensuring all keys are present, defaulting to None if missing\n",
        "            data_to_upsert = {\n",
        "                'Name': parish_data.get('Name'),\n",
        "                'Status': parish_data.get('Status'),\n",
        "                'Deanery': parish_data.get('Deanery'),\n",
        "                'EST': parish_data.get('EST'),\n",
        "                # Supabase table uses 'StreetAddress', JSON uses 'Street Address'\n",
        "                'StreetAddress': parish_data.get('Street Address'),\n",
        "                'City': parish_data.get('City'),\n",
        "                'State': parish_data.get('State'),\n",
        "                'Zipcode': parish_data.get('Zipcode'),\n",
        "                'PhoneNumber': parish_data.get('Phone Number'), # Supabase table uses 'PhoneNumber'\n",
        "                'Website': parish_data.get('Website'),\n",
        "                'source_url': parish_data['source_url'],\n",
        "                'domain': parish_data['domain']\n",
        "            }\n",
        "\n",
        "            try:\n",
        "                # Upsert into Parishes table. Assuming 'source_url' can be a unique identifier for upsert.\n",
        "                # If not, adjust conflict resolution or use insert.\n",
        "                # For now, using 'source_url' as the conflict target for an upsert.\n",
        "                # This implies 'source_url' column in 'Parishes' table must have a unique constraint.\n",
        "                response = supabase.table('Parishes').upsert(data_to_upsert, on_conflict='source_url').execute()\n",
        "\n",
        "                if hasattr(response, 'error') and response.error:\n",
        "                    print(f\"Error upserting data to Supabase for {url}: {response.error}\")\n",
        "                else:\n",
        "                    print(f\"Data upserted to Supabase for: {data_to_upsert.get('Name', 'Unknown Parish')} from {url}\")\n",
        "\n",
        "            except Exception as supa_error:\n",
        "                print(f\"Supabase API error during upsert for {url}: {supa_error}\")\n",
        "        elif not supabase:\n",
        "            print(f\"Supabase client not available. Skipping database write for {url}.\")\n",
        "        elif not parish_data:\n",
        "             print(f\"No data extracted for {url}. Skipping database write.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {url}: {str(e)}\")\n",
        "\n",
        "print(\"All URLs processed.\")"
      ],
      "metadata": {
        "id": "xlQd-ThXruqG",
        "outputId": "9da082f6-8b41-40d1-e819-7f624cd582ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing URL: https://www.diopueblo.org/parishes\n",
            "Gemini API Response: ```json\n",
            "{\n",
            "  \"Name\": null,\n",
            "  \"Status\": null,\n",
            "  \"Deanery\": null,\n",
            "  \"EST\": null,\n",
            "  \"Street Address\": null,\n",
            "  \"City\": null,\n",
            "  \"State\": null,\n",
            "  \"Zipcode\": null,\n",
            "  \"Phone Number\": null,\n",
            "  \"Website\": null\n",
            "}\n",
            "```\n",
            "\n",
            "Supabase API error during upsert for https://www.diopueblo.org/parishes: {'message': 'JSON could not be generated', 'code': 404, 'hint': 'Refer to full message for details', 'details': \"b'{}'\"}\n",
            "Processing URL: https://www.rcbo.org/directories/parishes/\n",
            "Gemini API Response: ```json\n",
            "{\n",
            "  \"Name\": null,\n",
            "  \"Status\": null,\n",
            "  \"Deanery\": null,\n",
            "  \"EST\": null,\n",
            "  \"Street Address\": null,\n",
            "  \"City\": null,\n",
            "  \"State\": null,\n",
            "  \"Zipcode\": null,\n",
            "  \"Phone Number\": null,\n",
            "  \"Website\": null\n",
            "}\n",
            "```\n",
            "\n",
            "Supabase API error during upsert for https://www.rcbo.org/directories/parishes/: {'message': 'JSON could not be generated', 'code': 404, 'hint': 'Refer to full message for details', 'details': \"b'{}'\"}\n",
            "Processing URL: https://archdiosf.org/directory-for-the-archdiocese\n",
            "Gemini API Response: ```json\n",
            "{\n",
            "  \"Name\": null,\n",
            "  \"Status\": null,\n",
            "  \"Deanery\": null,\n",
            "  \"EST\": null,\n",
            "  \"Street Address\": null,\n",
            "  \"City\": null,\n",
            "  \"State\": null,\n",
            "  \"Zipcode\": null,\n",
            "  \"Phone Number\": null,\n",
            "  \"Website\": null\n",
            "}\n",
            "```\n",
            "\n",
            "Supabase API error during upsert for https://archdiosf.org/directory-for-the-archdiocese: {'message': 'JSON could not be generated', 'code': 404, 'hint': 'Refer to full message for details', 'details': \"b'{}'\"}\n",
            "Processing URL: https://www.archbalt.org/parishes/\n",
            "Gemini API Response: ```json\n",
            "{}\n",
            "```\n",
            "The provided text is the website's introduction and navigation; it does not contain the requested parish information.  To extract that data, the entire parish directory page needs to be provided.\n",
            "\n",
            "JSON Decode Error: Extra data: line 2 column 1 (char 3)\n",
            "Raw API Response that failed parsing: ```json\n",
            "{}\n",
            "```\n",
            "The provided text is the website's introduction and navigation; it does not contain the requested parish information.  To extract that data, the entire parish directory page needs to be provided.\n",
            "\n",
            "Supabase API error during upsert for https://www.archbalt.org/parishes/: {'message': 'JSON could not be generated', 'code': 404, 'hint': 'Refer to full message for details', 'details': \"b'{}'\"}\n",
            "Processing URL: https://www.dioceseoftulsa.org/parishfinder\n",
            "Gemini API Response: ```json\n",
            "{\n",
            "  \"Name\": null,\n",
            "  \"Status\": null,\n",
            "  \"Deanery\": null,\n",
            "  \"EST\": null,\n",
            "  \"Street Address\": null,\n",
            "  \"City\": null,\n",
            "  \"State\": null,\n",
            "  \"Zipcode\": null,\n",
            "  \"Phone Number\": null,\n",
            "  \"Website\": null\n",
            "}\n",
            "```\n",
            "\n",
            "Supabase API error during upsert for https://www.dioceseoftulsa.org/parishfinder: {'message': 'JSON could not be generated', 'code': 404, 'hint': 'Refer to full message for details', 'details': \"b'{}'\"}\n",
            "All URLs processed.\n"
          ]
        }
      ]
    }
  ]
}